## RAGç³»ç»Ÿé¡¹ç›®

##### é¢˜ç›®ï¼šå¹²é¥­å†³ç­–å¤§å¸ˆ



##### ç®€ä»‹ï¼š

è¯¥é¡¹ç›®ä»¥ç»Ÿä¸€å°æ ‡é¢˜æ ¼å¼çš„ Markdown æ–‡ä»¶ï¼Œå®Œæ•´è®°å½•äº†ä»å®¶å¸¸èœåˆ°å®´å®¢èœçš„å„ç±»èœå“åˆ¶ä½œæ–¹æ³•ï¼Œæ¶µç›–åœºæ™¯ä¸°å¯Œã€æ ¼å¼è§„èŒƒã€‚ä¸ºè§£å†³ â€œä»Šå¤©åƒä»€ä¹ˆâ€ çš„é€‰æ‹©å›°éš¾ç—‡ï¼Œç¬”è€…èŒç”Ÿæ­å»ºæ™ºèƒ½é—®ç­”ç³»ç»Ÿçš„æƒ³æ³•ï¼Œæœ€ç»ˆæ‰“é€ å‡º â€œå¹²é¥­å†³ç­–å¤§å¸ˆâ€ RAG ç³»ç»Ÿï¼Œæ ¸å¿ƒåŠŸèƒ½ä¸ºæ ¹æ®ç”¨æˆ·éœ€æ±‚æ¨èé€‚é…èœå“ï¼Œå¹¶åŒæ­¥æä¾›è¯¦ç»†åˆ¶ä½œæ–¹æ³•ï¼Œç²¾å‡†ç ´è§£æ—¥å¸¸å¹²é¥­å†³ç­–éš¾é¢˜ã€‚



## æ­¥éª¤ï¼š

### ä¸€ã€å‰æœŸå‡†å¤‡

#### 1.1 ç¯å¢ƒæ­å»º

â€‹	ä½¿ç”¨condaåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```
# ä½¿ç”¨condaåˆ›å»ºç¯å¢ƒ
conda create -n cook-rag-1 python=3.12.7
conda activate cook-rag-1
```

â€‹	å®‰è£…ä¾èµ–

```
pip install -r requirements.txt
```

#### 1.2 apiæ¥å…¥

â€‹	æœ¬æ¬¡ä½¿ç”¨çš„æ˜¯kimiçš„api

â€‹	åœ¨kimiå®˜ç½‘ä¸Šæ³¨å†Œå¹¶ç”³è¯·apiï¼Œæœ‰å…è´¹çš„é¢åº¦

â€‹	æœ¬é¡¹ç›®åœ¨è…¾è®¯çš„cloud studioä¸Šè¿è¡Œï¼Œæ‰€ä»¥apiçš„é…ç½®ä¸æœ¬åœ°å¸ƒç½®æœ‰æ‰€ä¸åŒ

```
vim ~/.bashrc
```

â€‹	è¾“å…¥ i è¿›å…¥ç¼–è¾‘æ¨¡å¼ï¼Œåœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ä»¥ä¸‹è¡Œï¼Œå°† [ä½ çš„ kimi API å¯†é’¥] æ›¿æ¢ä¸ºä½ è‡ªå·±çš„å¯†é’¥ï¼š

```
export MOONSHOT_API_KEY=ä½ çš„kimi_api_key
```

â€‹	ä¿å­˜å¹¶é€€å‡º åœ¨ vim ä¸­ï¼ŒæŒ‰ Esc é”®è¿›å…¥å‘½ä»¤æ¨¡å¼ï¼Œç„¶åè¾“å…¥ :wq å¹¶æŒ‰ Enter é”®ä¿å­˜æ–‡ä»¶å¹¶é€€å‡ºã€‚

â€‹	ä½¿é…ç½®ç”Ÿæ•ˆ æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ¥ç«‹å³åŠ è½½æ›´æ–°åçš„é…ç½®ï¼Œè®©ç¯å¢ƒå˜é‡ç”Ÿæ•ˆï¼š

```
source ~/.bashrc
```

#### 1.3 é¡¹ç›®æ¶æ„

â”œâ”€â”€ config.py                   # é…ç½®ç®¡ç†
â”œâ”€â”€ main.py                     # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ rag_modules/               # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preparation.py    # æ•°æ®å‡†å¤‡æ¨¡å—
â”‚   â”œâ”€â”€ index_construction.py  # ç´¢å¼•æ„å»ºæ¨¡å—
â”‚   â”œâ”€â”€ retrieval_optimization.py # æ£€ç´¢ä¼˜åŒ–æ¨¡å—
â”‚   â””â”€â”€ generation_integration.py # ç”Ÿæˆé›†æˆæ¨¡å—
â””â”€â”€ vector_index/              # å‘é‡ç´¢å¼•ç¼“å­˜ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰



### äºŒã€æ•°æ®å‡†å¤‡

æœ¬é¡¹ç›®åŒ…å«300å¤šä¸ªMarkdownæ ¼å¼çš„èœè°±æ–‡ä»¶ã€‚è¿™äº›èœè°±æœ‰ä¸¤ä¸ªå…³é”®ç‰¹ç‚¹ï¼šä¸€æ˜¯ç»“æ„é«˜åº¦è§„æ•´ï¼Œæ¯ä¸ªæ–‡ä»¶éƒ½ä¸¥æ ¼æŒ‰ç…§ç»Ÿä¸€çš„æ ¼å¼æ¥ç»„ç»‡å†…å®¹ï¼›äºŒæ˜¯å†…å®¹ç¯‡å¹…è¾ƒçŸ­ï¼Œå•ä¸ªèœè°±é€šå¸¸åœ¨700å­—å·¦å³ã€‚

æ‰“å¼€ä»»æ„ä¸€ä¸ªèœè°±æ–‡ä»¶ï¼Œå¯ä»¥å‘ç°å®ƒä»¬éƒ½éµå¾ªç€ç›¸ä¼¼çš„ç»“æ„æ¨¡å¼ã€‚é€šå¸¸ä»¥èœå“åšæ³•ä½œä¸ºä¸€çº§æ ‡é¢˜ï¼Œå¼€å¤´ä¼šæœ‰ä¸€æ®µç®€ä»‹å’Œéš¾åº¦è¯„çº§ï¼Œç„¶ååˆ†ä¸º"å¿…å¤‡åŸæ–™å’Œå·¥å…·"ã€"è®¡ç®—"ã€"æ“ä½œ"ã€"é™„åŠ å†…å®¹"ç­‰å‡ ä¸ªä¸»è¦éƒ¨åˆ†ã€‚æ¯”å¦‚è¥¿çº¢æŸ¿ç‚’é¸¡è›‹è¿™é“èœï¼š

```markdown
# è¥¿çº¢æŸ¿ç‚’é¸¡è›‹çš„åšæ³•

è¥¿çº¢æŸ¿ç‚’è›‹æ˜¯ä¸­å›½å®¶å¸¸å‡ ä¹æœ€å¸¸è§çš„ä¸€é“èœè‚´...
é¢„ä¼°çƒ¹é¥ªéš¾åº¦ï¼šâ˜…â˜…

## å¿…å¤‡åŸæ–™å’Œå·¥å…·
* è¥¿çº¢æŸ¿
* é¸¡è›‹
* é£Ÿç”¨æ²¹...

## è®¡ç®—
æ¯æ¬¡åˆ¶ä½œå‰éœ€è¦ç¡®å®šè®¡åˆ’åšå‡ ä»½...
* è¥¿çº¢æŸ¿ = 1 ä¸ªï¼ˆçº¦ 180gï¼‰ * ä»½æ•°
* é¸¡è›‹ = 1.5 ä¸ª * ä»½æ•°ï¼Œå‘ä¸Šå–æ•´...

## æ“ä½œ
- è¥¿çº¢æŸ¿æ´—å‡€
- å¯é€‰ï¼šå»æ‰è¥¿çº¢æŸ¿çš„å¤–è¡¨çš®...

## é™„åŠ å†…å®¹
è¿™é“èœæ ¹æ®ä¸åŒçš„å£å‘³åå¥½ï¼Œå­˜åœ¨è¯¸å¤šç‰ˆæœ¬...
```

è™½ç„¶Markdownç»“æ„åˆ†å—çœ‹èµ·æ¥å¾ˆç†æƒ³ï¼Œä½†åœ¨å®é™…ä½¿ç”¨ä¸­å¯èƒ½ä¼šé‡åˆ°ä¸€ä¸ªé—®é¢˜ï¼šæŒ‰ç…§æ ‡é¢˜ä¸¥æ ¼åˆ†å—ä¼šæŠŠå†…å®¹åˆ‡å¾—å¤ªç»†ï¼Œå¯¼è‡´ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸å®Œæ•´ã€‚æ¯”å¦‚ç”¨æˆ·é—®"å®«ä¿é¸¡ä¸æ€ä¹ˆåš"ï¼Œå¦‚æœä¸¥æ ¼æŒ‰æ ‡é¢˜åˆ†å—ï¼Œå¯èƒ½åªæ£€ç´¢åˆ°"æ“ä½œ"è¿™ä¸€ä¸ªç« èŠ‚ï¼Œä½†ç¼ºå°‘äº†"å¿…å¤‡åŸæ–™å’Œå·¥å…·"çš„ä¿¡æ¯ï¼ŒLLMå°±æ— æ³•ç»™å‡ºå®Œæ•´çš„åˆ¶ä½œæŒ‡å¯¼ã€‚ç”šè‡³æœ‰æ—¶å€™æ£€ç´¢åˆ°çš„æ˜¯"é™„åŠ å†…å®¹"ä¸­çš„æŸä¸ªå˜åŒ–åšæ³•ï¼Œæ²¡æœ‰åŸºç¡€åˆ¶ä½œæ­¥éª¤ï¼Œå›ç­”å°±ä¼šæ˜¾å¾—è«åå…¶å¦™ã€‚å¦‚æœä½ å°è¯•ç›´æ¥æŠŠæ•´ä¸ªèœè°±æ–‡æ¡£ä½œä¸ºä¸€ä¸ªå—ï¼Œå¯ä»¥å‘ç°æ•ˆæœåè€Œæ¯”ç»“æ„åˆ†å—è¦å¥½ï¼Œå› ä¸ºä¸Šä¸‹æ–‡ä¿¡æ¯æ˜¯å®Œæ•´çš„ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªçŸ›ç›¾ï¼Œå¯ä»¥é‡‡ç”¨çˆ¶å­æ–‡æœ¬å—çš„ç­–ç•¥ï¼šç”¨å°çš„å­å—è¿›è¡Œç²¾ç¡®æ£€ç´¢ï¼Œä½†åœ¨ç”Ÿæˆæ—¶ä¼ é€’å®Œæ•´çš„çˆ¶æ–‡æ¡£ç»™LLMã€‚è¿™ç§æ–¹æ³•åœ¨ç¬¬3ç« çš„ç´¢å¼•ä¼˜åŒ–ä¸­è™½ç„¶æ²¡æœ‰ä¸“é—¨ä»‹ç»ï¼Œä½†æœ¬è´¨ä¸Šä¹Ÿå±äºä¸Šä¸‹æ–‡æ‹“å±•çš„ä¸€ç§åº”ç”¨ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬æ—¢ä¿è¯äº†æ£€ç´¢çš„ç²¾ç¡®æ€§ï¼Œåˆç¡®ä¿äº†ç”Ÿæˆæ—¶ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§ã€‚

æ•°æ®å‡†å¤‡æ¨¡å—çš„æ ¸å¿ƒæ˜¯å®ç°"å°å—æ£€ç´¢ï¼Œå¤§å—ç”Ÿæˆ"çš„çˆ¶å­æ–‡æœ¬å—æ¶æ„ã€‚

**çˆ¶å­æ–‡æœ¬å—æ˜ å°„å…³ç³»**ï¼š

```
çˆ¶æ–‡æ¡£ï¼ˆå®Œæ•´èœè°±ï¼‰
â”œâ”€â”€ å­å—1ï¼šèœå“ä»‹ç» + éš¾åº¦è¯„çº§
â”œâ”€â”€ å­å—2ï¼šå¿…å¤‡åŸæ–™å’Œå·¥å…·
â”œâ”€â”€ å­å—3ï¼šè®¡ç®—ï¼ˆç”¨é‡é…æ¯”ï¼‰
â”œâ”€â”€ å­å—4ï¼šæ“ä½œï¼ˆåˆ¶ä½œæ­¥éª¤ï¼‰
â””â”€â”€ å­å—5ï¼šé™„åŠ å†…å®¹ï¼ˆå˜åŒ–åšæ³•ï¼‰
```



### ä¸‰ã€æ•°æ®å¤„ç†æ¨¡å—å®ç°

#### 3.1 ç±»ç»“æ„è®¾è®¡

```python
class DataPreparationModule:
    """æ•°æ®å‡†å¤‡æ¨¡å— - è´Ÿè´£æ•°æ®åŠ è½½ã€æ¸…æ´—å’Œé¢„å¤„ç†"""

    def __init__(self, data_path: str):
        self.data_path = data_path
        self.documents: List[Document] = []  # çˆ¶æ–‡æ¡£ï¼ˆå®Œæ•´é£Ÿè°±ï¼‰
        self.chunks: List[Document] = []     # å­æ–‡æ¡£ï¼ˆæŒ‰æ ‡é¢˜åˆ†å‰²çš„å°å—ï¼‰
        self.parent_child_map: Dict[str, str] = {}  # å­å—ID -> çˆ¶æ–‡æ¡£IDçš„æ˜ å°„
```

- `documents`: å­˜å‚¨å®Œæ•´çš„èœè°±æ–‡æ¡£ï¼ˆçˆ¶æ–‡æ¡£ï¼‰
- `chunks`: å­˜å‚¨æŒ‰æ ‡é¢˜åˆ†å‰²çš„å°å—ï¼ˆå­æ–‡æ¡£ï¼‰
- `parent_child_map`: ç»´æŠ¤çˆ¶å­å…³ç³»æ˜ å°„

#### 3.2 æ–‡æ¡£åŠ è½½å®ç°

#### 3.2.1 æ‰¹é‡åŠ è½½Markdownæ–‡ä»¶

```python
def load_documents(self) -> List[Document]:
    """åŠ è½½æ–‡æ¡£æ•°æ®"""
    documents = []
    data_path_obj = Path(self.data_path)

    for md_file in data_path_obj.rglob("*.md"):
        # è¯»å–æ–‡ä»¶å†…å®¹ï¼Œä¿æŒMarkdownæ ¼å¼
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # ä¸ºæ¯ä¸ªçˆ¶æ–‡æ¡£åˆ†é…å”¯ä¸€ID
        parent_id = str(uuid.uuid4())

        # åˆ›å»ºDocumentå¯¹è±¡
        doc = Document(
            page_content=content,
            metadata={
                "source": str(md_file),
                "parent_id": parent_id,
                "doc_type": "parent"  # æ ‡è®°ä¸ºçˆ¶æ–‡æ¡£
            }
        )
        documents.append(doc)

    # å¢å¼ºæ–‡æ¡£å…ƒæ•°æ®
    for doc in documents:
        self._enhance_metadata(doc)

    self.documents = documents
    return documents
```

- `rglob("*.md")`: é€’å½’æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶
- `parent_id`: ä¸ºæ¯ä¸ªçˆ¶æ–‡æ¡£åˆ†é…å”¯ä¸€IDï¼Œå»ºç«‹çˆ¶å­å…³ç³»çš„å…³é”®
- `doc_type`: æ ‡è®°ä¸º"parent"ï¼Œä¾¿äºåŒºåˆ†çˆ¶å­æ–‡æ¡£

#### 3.2.2 å…ƒæ•°æ®å¢å¼º

```python
def _enhance_metadata(self, doc: Document):
    """å¢å¼ºæ–‡æ¡£å…ƒæ•°æ®"""
    file_path = Path(doc.metadata.get('source', ''))
    path_parts = file_path.parts

    # æå–èœå“åˆ†ç±»
    category_mapping = {
        'meat_dish': 'è¤èœ', 'vegetable_dish': 'ç´ èœ', 'soup': 'æ±¤å“',
        'dessert': 'ç”œå“', 'breakfast': 'æ—©é¤', 'staple': 'ä¸»é£Ÿ',
        'aquatic': 'æ°´äº§', 'condiment': 'è°ƒæ–™', 'drink': 'é¥®å“'
    }

    # ä»æ–‡ä»¶è·¯å¾„æ¨æ–­åˆ†ç±»
    doc.metadata['category'] = 'å…¶ä»–'
    for key, value in category_mapping.items():
        if key in file_path.parts:
            doc.metadata['category'] = value
            break

    # æå–èœå“åç§°
    doc.metadata['dish_name'] = file_path.stem

    # åˆ†æéš¾åº¦ç­‰çº§
    content = doc.page_content
    if 'â˜…â˜…â˜…â˜…â˜…' in content:
        doc.metadata['difficulty'] = 'éå¸¸å›°éš¾'
    elif 'â˜…â˜…â˜…â˜…' in content:
        doc.metadata['difficulty'] = 'å›°éš¾'
    # ... (å…¶ä»–éš¾åº¦ç­‰çº§åˆ¤æ–­)

```

- **åˆ†ç±»æ¨æ–­**: ä»é¡¹ç›®çš„ç›®å½•ç»“æ„æ¨æ–­èœå“åˆ†ç±»
- **éš¾åº¦æå–**: ä»å†…å®¹ä¸­çš„æ˜Ÿçº§æ ‡è®°è‡ªåŠ¨æå–éš¾åº¦ç­‰çº§
- **åç§°æå–**: ç›´æ¥ä½¿ç”¨æ–‡ä»¶åä½œä¸ºèœå“åç§°

#### 3.3 Markdownç»“æ„åˆ†å—

å°†å®Œæ•´çš„èœè°±æ–‡æ¡£æŒ‰ç…§Markdownæ ‡é¢˜ç»“æ„è¿›è¡Œåˆ†å—ï¼Œå®ç°çˆ¶å­æ–‡æœ¬å—æ¶æ„ã€‚

#### 3.3.1 åˆ†å—ç­–ç•¥

```python
def chunk_documents(self) -> List[Document]:
    """Markdownç»“æ„æ„ŸçŸ¥åˆ†å—"""
    if not self.documents:
        raise ValueError("è¯·å…ˆåŠ è½½æ–‡æ¡£")

    # ä½¿ç”¨Markdownæ ‡é¢˜åˆ†å‰²å™¨
    chunks = self._markdown_header_split()

    # ä¸ºæ¯ä¸ªchunkæ·»åŠ åŸºç¡€å…ƒæ•°æ®
    for i, chunk in enumerate(chunks):
        if 'chunk_id' not in chunk.metadata:
            # å¦‚æœæ²¡æœ‰chunk_idï¼ˆæ¯”å¦‚åˆ†å‰²å¤±è´¥çš„æƒ…å†µï¼‰ï¼Œåˆ™ç”Ÿæˆä¸€ä¸ª
            chunk.metadata['chunk_id'] = str(uuid.uuid4())
        chunk.metadata['batch_index'] = i  # åœ¨å½“å‰æ‰¹æ¬¡ä¸­çš„ç´¢å¼•
        chunk.metadata['chunk_size'] = len(chunk.page_content)

    self.chunks = chunks
    return chunks
```

#### 3.3.2 Markdownæ ‡é¢˜åˆ†å‰²å™¨

```python
def _markdown_header_split(self) -> List[Document]:
    """ä½¿ç”¨Markdownæ ‡é¢˜åˆ†å‰²å™¨è¿›è¡Œç»“æ„åŒ–åˆ†å‰²"""
    # å®šä¹‰è¦åˆ†å‰²çš„æ ‡é¢˜å±‚çº§
    headers_to_split_on = [
        ("#", "ä¸»æ ‡é¢˜"),      # èœå“åç§°
        ("##", "äºŒçº§æ ‡é¢˜"),   # å¿…å¤‡åŸæ–™ã€è®¡ç®—ã€æ“ä½œç­‰
        ("###", "ä¸‰çº§æ ‡é¢˜")   # ç®€æ˜“ç‰ˆæœ¬ã€å¤æ‚ç‰ˆæœ¬ç­‰
    ]

    # åˆ›å»ºMarkdownåˆ†å‰²å™¨
    markdown_splitter = MarkdownHeaderTextSplitter(
        headers_to_split_on=headers_to_split_on,
        strip_headers=False  # ä¿ç•™æ ‡é¢˜ï¼Œä¾¿äºç†è§£ä¸Šä¸‹æ–‡
    )

    all_chunks = []
    for doc in self.documents:
        # å¯¹æ¯ä¸ªæ–‡æ¡£è¿›è¡ŒMarkdownåˆ†å‰²
        md_chunks = markdown_splitter.split_text(doc.page_content)

        # ä¸ºæ¯ä¸ªå­å—å»ºç«‹ä¸çˆ¶æ–‡æ¡£çš„å…³ç³»
        parent_id = doc.metadata["parent_id"]

        for i, chunk in enumerate(md_chunks):
            # ä¸ºå­å—åˆ†é…å”¯ä¸€IDå¹¶å»ºç«‹çˆ¶å­å…³ç³»
            child_id = str(uuid.uuid4())
            chunk.metadata.update(doc.metadata)
            chunk.metadata.update({
                "chunk_id": child_id,
                "parent_id": parent_id,
                "doc_type": "child",  # æ ‡è®°ä¸ºå­æ–‡æ¡£
                "chunk_index": i      # åœ¨çˆ¶æ–‡æ¡£ä¸­çš„ä½ç½®
            })

            # å»ºç«‹çˆ¶å­æ˜ å°„å…³ç³»
            self.parent_child_map[child_id] = parent_id

        all_chunks.extend(md_chunks)

    return all_chunks
```

- **ä¸‰çº§æ ‡é¢˜åˆ†å‰²**: æŒ‰ç…§`#`ã€`##`ã€`###`è¿›è¡Œå±‚çº§åˆ†å‰²
- **ä¿ç•™æ ‡é¢˜**: è®¾ç½®`strip_headers=False`ï¼Œä¿ç•™æ ‡é¢˜ä¿¡æ¯ä¾¿äºç†è§£ä¸Šä¸‹æ–‡
- **çˆ¶å­å…³ç³»**: æ¯ä¸ªå­å—éƒ½è®°å½•å…¶çˆ¶æ–‡æ¡£çš„`parent_id`
- **å”¯ä¸€æ ‡è¯†**: æ¯ä¸ªå­å—éƒ½æœ‰ç‹¬ç«‹çš„`child_id`

#### 3.3.3 åˆ†å—æ•ˆæœç¤ºä¾‹

ä»¥"è¥¿çº¢æŸ¿ç‚’é¸¡è›‹"ä¸ºä¾‹ï¼Œåˆ†å—åçš„æ•ˆæœï¼š

```
åŸæ–‡æ¡£ï¼šè¥¿çº¢æŸ¿ç‚’é¸¡è›‹çš„åšæ³•.md (çˆ¶æ–‡æ¡£)
â”œâ”€â”€ å­å—1ï¼š# è¥¿çº¢æŸ¿ç‚’é¸¡è›‹çš„åšæ³• + ç®€ä»‹ + éš¾åº¦è¯„çº§
â”œâ”€â”€ å­å—2ï¼š## å¿…å¤‡åŸæ–™å’Œå·¥å…· + é£Ÿææ¸…å•
â”œâ”€â”€ å­å—3ï¼š## è®¡ç®— + ç”¨é‡é…æ¯”å…¬å¼
â”œâ”€â”€ å­å—4ï¼š## æ“ä½œ + è¯¦ç»†åˆ¶ä½œæ­¥éª¤
â””â”€â”€ å­å—5ï¼š## é™„åŠ å†…å®¹
```

**åˆ†å—é€»è¾‘**ï¼š

- **å­å—1**: åŒ…å«ä¸€çº§æ ‡é¢˜åŠå…¶ä¸‹çš„æ‰€æœ‰å†…å®¹ï¼ˆç®€ä»‹ã€éš¾åº¦è¯„çº§ï¼‰ï¼Œç›´åˆ°é‡åˆ°ä¸‹ä¸€ä¸ªäºŒçº§æ ‡é¢˜
- **å­å—2-5**: æ¯ä¸ªäºŒçº§æ ‡é¢˜åŠå…¶ä¸‹çš„å†…å®¹å½¢æˆä¸€ä¸ªç‹¬ç«‹å­å—
- **ç²¾ç¡®æ£€ç´¢**: ç”¨æˆ·é—®"éœ€è¦ä»€ä¹ˆé£Ÿæ"æ—¶ï¼Œèƒ½ç²¾ç¡®åŒ¹é…åˆ°å­å—2
- **ä¸Šä¸‹æ–‡å®Œæ•´**: ç”Ÿæˆæ—¶ä¼ é€’å®Œæ•´çš„çˆ¶æ–‡æ¡£ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯

#### 3.4 æ™ºèƒ½å»é‡

å½“ç”¨æˆ·è¯¢é—®"å®«ä¿é¸¡ä¸æ€ä¹ˆåš"æ—¶ï¼Œå¯èƒ½ä¼šæ£€ç´¢åˆ°åŒä¸€é“èœçš„å¤šä¸ªå­å—ã€‚æˆ‘ä»¬éœ€è¦æ™ºèƒ½å»é‡ï¼Œé¿å…é‡å¤ä¿¡æ¯ã€‚

```python
def get_parent_documents(self, child_chunks: List[Document]) -> List[Document]:
    """æ ¹æ®å­å—è·å–å¯¹åº”çš„çˆ¶æ–‡æ¡£ï¼ˆæ™ºèƒ½å»é‡ï¼‰"""
    # ç»Ÿè®¡æ¯ä¸ªçˆ¶æ–‡æ¡£è¢«åŒ¹é…çš„æ¬¡æ•°ï¼ˆç›¸å…³æ€§æŒ‡æ ‡ï¼‰
    parent_relevance = {}
    parent_docs_map = {}

    # æ”¶é›†æ‰€æœ‰ç›¸å…³çš„çˆ¶æ–‡æ¡£IDå’Œç›¸å…³æ€§åˆ†æ•°
    for chunk in child_chunks:
        parent_id = chunk.metadata.get("parent_id")
        if parent_id:
            # å¢åŠ ç›¸å…³æ€§è®¡æ•°
            parent_relevance[parent_id] = parent_relevance.get(parent_id, 0) + 1

            # ç¼“å­˜çˆ¶æ–‡æ¡£ï¼ˆé¿å…é‡å¤æŸ¥æ‰¾ï¼‰
            if parent_id not in parent_docs_map:
                for doc in self.documents:
                    if doc.metadata.get("parent_id") == parent_id:
                        parent_docs_map[parent_id] = doc
                        break

    # æŒ‰ç›¸å…³æ€§æ’åºå¹¶æ„å»ºå»é‡åçš„çˆ¶æ–‡æ¡£åˆ—è¡¨
    sorted_parent_ids = sorted(parent_relevance.keys(),
                             key=lambda x: parent_relevance[x], reverse=True)

    # æ„å»ºå»é‡åçš„çˆ¶æ–‡æ¡£åˆ—è¡¨
    parent_docs = []
    for parent_id in sorted_parent_ids:
        if parent_id in parent_docs_map:
            parent_docs.append(parent_docs_map[parent_id])

    return parent_docs
```

**å»é‡é€»è¾‘**ï¼š

1. **ç»Ÿè®¡ç›¸å…³æ€§**: è®¡ç®—æ¯ä¸ªçˆ¶æ–‡æ¡£è¢«åŒ¹é…çš„å­å—æ•°é‡
2. **æŒ‰ç›¸å…³æ€§æ’åº**: åŒ¹é…å­å—è¶Šå¤šçš„èœè°±æ’åè¶Šé å‰
3. **å»é‡è¾“å‡º**: æ¯ä¸ªèœè°±åªè¾“å‡ºä¸€æ¬¡å®Œæ•´æ–‡æ¡£



### å››ã€ç´¢å¼•æ„å»ºå’Œæ£€ç´¢ä¼˜åŒ–

#### 4.1.1 ç´¢å¼•æ„å»º

ç´¢å¼•æ„å»ºæ¨¡å—çš„æ ¸å¿ƒä»»åŠ¡æ˜¯å°†æ–‡æœ¬å—è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºï¼Œå¹¶æ„å»ºé«˜æ•ˆçš„æ£€ç´¢ç´¢å¼•ã€‚è¿™é‡Œé€‰æ‹©ä¹‹å‰ä¸€ç›´ä½¿ç”¨çš„BGE-small-zh-v1.5ä½œä¸ºåµŒå…¥æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨FAISSä½œä¸ºå‘é‡æ•°æ®åº“æ¥å­˜å‚¨å’Œæ£€ç´¢å‘é‡ã€‚ä¸ºäº†æå‡ç³»ç»Ÿå¯åŠ¨é€Ÿåº¦ï¼Œå®ç°ç´¢å¼•ç¼“å­˜æœºåˆ¶ã€‚é¦–æ¬¡æ„å»ºåä¼šå°†FAISSç´¢å¼•ä¿å­˜åˆ°æœ¬åœ°ï¼Œåç»­å¯åŠ¨æ—¶ç›´æ¥åŠ è½½å·²æœ‰ç´¢å¼•ï¼Œå¯ä»¥å°†å¯åŠ¨æ—¶é—´ä»å‡ åˆ†é’Ÿç¼©çŸ­åˆ°å‡ ç§’é’Ÿã€‚

#### 4.1.2 æ··åˆæ£€ç´¢

æ£€ç´¢ä¼˜åŒ–æ¨¡å—å®ç°äº†å¤šç§æ£€ç´¢ç­–ç•¥çš„ç»„åˆã€‚é‡‡ç”¨åŒè·¯æ£€ç´¢çš„æ–¹å¼ï¼šå‘é‡æ£€ç´¢åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œæ“…é•¿ç†è§£æŸ¥è¯¢æ„å›¾ï¼›BM25æ£€ç´¢åŸºäºå…³é”®è¯åŒ¹é…ï¼Œæ“…é•¿ç²¾ç¡®åŒ¹é…ã€‚ä¸ºäº†ç»¼åˆä¸¤ç§æ£€ç´¢æ–¹å¼çš„ä¼˜åŠ¿ï¼Œæˆ‘ä»¬ä½¿ç”¨RRFï¼ˆReciprocal Rank Fusionï¼‰ç®—æ³•æ¥èåˆæ£€ç´¢ç»“æœã€‚è¿™ä¸ªç®—æ³•ä¼šç»¼åˆè€ƒè™‘ä¸¤ç§æ£€ç´¢ç»“æœçš„æ’åä¿¡æ¯ï¼Œé¿å…è¿‡åº¦ä¾èµ–å•ä¸€æ£€ç´¢æ–¹å¼ã€‚

#### 4.2.1 ç±»ç»“æ„è®¾è®¡

```python
class IndexConstructionModule:
    """ç´¢å¼•æ„å»ºæ¨¡å— - è´Ÿè´£å‘é‡åŒ–å’Œç´¢å¼•æ„å»º"""

    def __init__(self, model_name: str = "BAAI/bge-small-zh-v1.5",
                 index_save_path: str = "./vector_index"):
        self.model_name = model_name
        self.index_save_path = index_save_path
        self.embeddings = None
        self.vectorstore = None
        self.setup_embeddings()
```

- `index_save_path`: ç´¢å¼•ä¿å­˜è·¯å¾„
- `embeddings`: HuggingFaceåµŒå…¥æ¨¡å‹å®ä¾‹
- `vectorstore`: FAISSå‘é‡å­˜å‚¨å®ä¾‹



#### 4.2.2 åµŒå…¥æ¨¡å‹åˆå§‹åŒ–

```python
def setup_embeddings(self):
    """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹"""
    self.embeddings = HuggingFaceEmbeddings(
        model_name=self.model_name,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
```

#### 4.2.3 å‘é‡ç´¢å¼•æ„å»º

```python
def build_vector_index(self, chunks: List[Document]) -> FAISS:
    """æ„å»ºå‘é‡ç´¢å¼•"""
    if not chunks:
        raise ValueError("æ–‡æ¡£å—åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    
    # æå–æ–‡æœ¬å†…å®¹
    texts = [chunk.page_content for chunk in chunks]
    metadatas = [chunk.metadata for chunk in chunks]
    
    # æ„å»ºFAISSå‘é‡ç´¢å¼•
    self.vectorstore = FAISS.from_texts(
        texts=texts,
        embedding=self.embeddings,
        metadatas=metadatas
    )
    
    return self.vectorstore
```

ä½¿ç”¨FAISSä½œä¸ºå‘é‡æ•°æ®åº“ï¼Œå®ƒçš„æ£€ç´¢é€Ÿåº¦å¾ˆå¿«ï¼ŒåŒæ—¶ä¿å­˜äº†æ–‡æœ¬å†…å®¹å’Œå…ƒæ•°æ®ä¿¡æ¯ï¼Œæ”¯æŒå¤§è§„æ¨¡å‘é‡çš„é«˜æ•ˆæ£€ç´¢ã€‚

#### 4.2.4 ç´¢å¼•ç¼“å­˜æœºåˆ¶

```python
def save_index(self):
    """ä¿å­˜å‘é‡ç´¢å¼•åˆ°é…ç½®çš„è·¯å¾„"""
    if not self.vectorstore:
        raise ValueError("è¯·å…ˆæ„å»ºå‘é‡ç´¢å¼•")
    
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    Path(self.index_save_path).mkdir(parents=True, exist_ok=True)
    
    self.vectorstore.save_local(self.index_save_path)

def load_index(self):
    """ä»é…ç½®çš„è·¯å¾„åŠ è½½å‘é‡ç´¢å¼•"""
    if not self.embeddings:
        self.setup_embeddings()
    
    if not Path(self.index_save_path).exists():
        return None
    
    self.vectorstore = FAISS.load_local(
        self.index_save_path, 
        self.embeddings,
        allow_dangerous_deserialization=True
    )
    return self.vectorstore
```

ç´¢å¼•ç¼“å­˜çš„æ•ˆæœå¾ˆæ˜æ˜¾ï¼šé¦–æ¬¡è¿è¡Œæ—¶æ„å»ºç´¢å¼•éœ€è¦å‡ åˆ†é’Ÿï¼Œä½†åç»­è¿è¡Œæ—¶åŠ è½½ç´¢å¼•åªéœ€å‡ ç§’é’Ÿã€‚ç´¢å¼•æ–‡ä»¶é€šå¸¸åªæœ‰å‡ åMBï¼Œå­˜å‚¨æ•ˆç‡å¾ˆé«˜ã€‚



#### 4.3.1 ç±»ç»“æ„è®¾è®¡

```python
class RetrievalOptimizationModule:
    """æ£€ç´¢ä¼˜åŒ–æ¨¡å— - è´Ÿè´£æ··åˆæ£€ç´¢å’Œè¿‡æ»¤"""

    def __init__(self, vectorstore: FAISS, chunks: List[Document]):
        self.vectorstore = vectorstore
        self.chunks = chunks
        self.setup_retrievers()
```

- `vectorstore`: FAISSå‘é‡å­˜å‚¨å®ä¾‹
- `chunks`: æ–‡æ¡£å—åˆ—è¡¨ï¼Œç”¨äºBM25æ£€ç´¢

#### 4.3.2 æ£€ç´¢å™¨è®¾ç½®

```python
def setup_retrievers(self):
    """è®¾ç½®å‘é‡æ£€ç´¢å™¨å’ŒBM25æ£€ç´¢å™¨"""
    # å‘é‡æ£€ç´¢å™¨
    self.vector_retriever = self.vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 5}
    )

    # BM25æ£€ç´¢å™¨
    self.bm25_retriever = BM25Retriever.from_documents(
        self.chunks,
        k=5
    )
```

#### 4.3.3 RRFæ··åˆæ£€ç´¢

```python
def hybrid_search(self, query: str, top_k: int = 3) -> List[Document]:
    """æ··åˆæ£€ç´¢ - ç»“åˆå‘é‡æ£€ç´¢å’ŒBM25æ£€ç´¢ï¼Œä½¿ç”¨RRFé‡æ’"""
    # åˆ†åˆ«è·å–å‘é‡æ£€ç´¢å’ŒBM25æ£€ç´¢ç»“æœ
    vector_docs = self.vector_retriever.get_relevant_documents(query)
    bm25_docs = self.bm25_retriever.get_relevant_documents(query)

    # ä½¿ç”¨RRFé‡æ’
    reranked_docs = self._rrf_rerank(vector_docs, bm25_docs)
    return reranked_docs[:top_k]

def _rrf_rerank(self, vector_results: List[Document], bm25_results: List[Document]) -> List[Document]:
    """RRF (Reciprocal Rank Fusion) é‡æ’"""
    
    # RRFèåˆç®—æ³•
    rrf_scores = {}
    k = 60  # RRFå‚æ•°
    
    # è®¡ç®—å‘é‡æ£€ç´¢çš„RRFåˆ†æ•°
    for rank, doc in enumerate(vector_results):
        doc_id = id(doc)
        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1 / (k + rank + 1)

    # è®¡ç®—BM25æ£€ç´¢çš„RRFåˆ†æ•°
    for rank, doc in enumerate(bm25_results):
        doc_id = id(doc)
        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1 / (k + rank + 1)

    # åˆå¹¶æ‰€æœ‰æ–‡æ¡£å¹¶æŒ‰RRFåˆ†æ•°æ’åº
    all_docs = {id(doc): doc for doc in vector_results + bm25_results}
    sorted_docs = sorted(all_docs.items(),
                        key=lambda x: rrf_scores.get(x[0], 0),
                        reverse=True)

    return [doc for _, doc in sorted_docs]
```

åœ¨å½“å‰ç³»ç»Ÿä¸­ï¼Œä¸¤ç§æ£€ç´¢æ–¹å¼å„æœ‰ä¼˜åŠ¿ï¼š

**å‘é‡æ£€ç´¢çš„ä¼˜åŠ¿**ï¼š

- ç†è§£è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œå¦‚"ç®€å•æ˜“åšçš„èœ"èƒ½åŒ¹é…åˆ°æ ‡è®°ä¸º"ç®€å•"çš„èœè°±
- å¤„ç†åŒä¹‰è¯å’Œè¿‘ä¹‰è¯ï¼Œå¦‚"åˆ¶ä½œæ–¹æ³•"å’Œ"åšæ³•"ã€"çƒ¹é¥ªæ­¥éª¤"
- ç†è§£ç”¨æˆ·æ„å›¾ï¼Œå¦‚"é€‚åˆæ–°æ‰‹"èƒ½æ‰¾åˆ°éš¾åº¦è¾ƒä½çš„èœè°±

**BM25æ£€ç´¢çš„ä¼˜åŠ¿**ï¼š

- ç²¾ç¡®åŒ¹é…èœåï¼Œå¦‚"å®«ä¿é¸¡ä¸"èƒ½å‡†ç¡®æ‰¾åˆ°å¯¹åº”èœè°±
- åŒ¹é…å…·ä½“é£Ÿæï¼Œå¦‚"åœŸè±†ä¸"ã€"è¥¿çº¢æŸ¿"ç­‰å…³é”®è¯
- å¤„ç†ä¸“ä¸šæœ¯è¯­ï¼Œå¦‚"çˆ†ç‚’"ã€"çº¢çƒ§"ç­‰çƒ¹é¥ªæ‰‹æ³•

RRFç®—æ³•èƒ½ç»¼åˆä¸¤ç§æ£€ç´¢æ–¹å¼çš„æ’åä¿¡æ¯ï¼Œæ—¢ä¿è¯äº†è¯­ä¹‰ç†è§£çš„å‡†ç¡®æ€§ï¼Œåˆç¡®ä¿äº†å…³é”®è¯åŒ¹é…çš„ç²¾ç¡®æ€§ã€‚å½“ç„¶è¿˜å¯ä»¥ç”¨è·¯ç”±çš„æ–¹å¼ï¼Œæ ¹æ®æŸ¥è¯¢ç±»å‹æ™ºèƒ½é€‰æ‹©ä½¿ç”¨å‘é‡æ£€ç´¢è¿˜æ˜¯BM25æ£€ç´¢ã€‚è¿™ç§æ–¹æ³•é’ˆå¯¹æ€§å¼ºï¼Œèƒ½ä¸ºä¸åŒç±»å‹çš„æŸ¥è¯¢é€‰æ‹©æœ€ä¼˜çš„æ£€ç´¢æ–¹å¼ï¼›ä¸è¶³æ˜¯è·¯ç”±è§„åˆ™çš„è®¾è®¡å’Œç»´æŠ¤æ¯”è¾ƒå¤æ‚ï¼Œè¾¹ç•Œæƒ…å†µéš¾ä»¥å¤„ç†ï¼Œè€Œä¸”é€šå¸¸éœ€è¦è°ƒç”¨LLMæ¥åˆ¤æ–­æŸ¥è¯¢ç±»å‹ï¼Œä¼šå¢åŠ å»¶è¿Ÿå’Œæˆæœ¬ã€‚

#### 4.3.4 å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢

```python
def metadata_filtered_search(self, query: str, filters: Dict[str, Any],
                           top_k: int = 5) -> List[Document]:
    """åŸºäºå…ƒæ•°æ®è¿‡æ»¤çš„æ£€ç´¢"""
    # å…ˆè¿›è¡Œå‘é‡æ£€ç´¢
    vector_retriever = self.vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": top_k * 3, "filter": filters}  # æ‰©å¤§æ£€ç´¢èŒƒå›´
    )

    results = vector_retriever.invoke(query)
    return results[:top_k]
```

**è¿‡æ»¤æ£€ç´¢åº”ç”¨åœºæ™¯**ï¼š

- ç”¨æˆ·è¯¢é—®"æ¨èå‡ é“ç´ èœ"æ—¶ï¼Œå¯ä»¥æŒ‰èœå“åˆ†ç±»è¿‡æ»¤ï¼Œåªæ£€ç´¢ç´ èœç›¸å…³çš„å†…å®¹
- æ–°æ‰‹ç”¨æˆ·é—®"æœ‰ä»€ä¹ˆç®€å•çš„èœè°±"æ—¶ï¼Œå¯ä»¥æŒ‰éš¾åº¦ç­‰çº§è¿‡æ»¤ï¼Œåªè¿”å›æ ‡è®°ä¸º"ç®€å•"çš„èœè°±
- æƒ³åšæ±¤å“æ—¶è¯¢é—®"ä»Šå¤©å–ä»€ä¹ˆæ±¤"ï¼Œå¯ä»¥æŒ‰åˆ†ç±»è¿‡æ»¤å‡ºæ‰€æœ‰æ±¤å“èœè°±



### äº”ã€ç”Ÿæˆé›†æˆæ¨¡å—

ç”Ÿæˆé›†æˆæ¨¡å—æ˜¯æ•´ä¸ªRAGç³»ç»Ÿçš„"å¤§è„‘"ï¼Œè´Ÿè´£ç†è§£ç”¨æˆ·æ„å›¾ã€è·¯ç”±æŸ¥è¯¢ç±»å‹ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›ç­”ã€‚

#### 5.1.1 è®¾è®¡æ€è·¯

**æ™ºèƒ½æŸ¥è¯¢è·¯ç”±**ï¼šæ ¹æ®ç”¨æˆ·æŸ¥è¯¢è‡ªåŠ¨åˆ¤æ–­æ˜¯åˆ—è¡¨æŸ¥è¯¢ã€è¯¦ç»†æŸ¥è¯¢è¿˜æ˜¯ä¸€èˆ¬æŸ¥è¯¢ï¼Œé€‰æ‹©æœ€é€‚åˆçš„ç”Ÿæˆç­–ç•¥ã€‚

**æŸ¥è¯¢é‡å†™ä¼˜åŒ–**ï¼šå¯¹æ¨¡ç³Šä¸æ¸…çš„æŸ¥è¯¢è¿›è¡Œæ™ºèƒ½é‡å†™ï¼Œæå‡æ£€ç´¢æ•ˆæœã€‚æ¯”å¦‚å°†"åšèœ"é‡å†™ä¸º"ç®€å•æ˜“åšçš„å®¶å¸¸èœè°±"ã€‚

**å¤šæ¨¡å¼ç”Ÿæˆ**ï¼š

- **åˆ—è¡¨æ¨¡å¼**ï¼šé€‚ç”¨äºæ¨èç±»æŸ¥è¯¢ï¼Œè¿”å›ç®€æ´çš„èœå“åˆ—è¡¨
- **è¯¦ç»†æ¨¡å¼**ï¼šé€‚ç”¨äºåˆ¶ä½œç±»æŸ¥è¯¢ï¼Œæä¾›åˆ†æ­¥éª¤çš„è¯¦ç»†æŒ‡å¯¼
- **åŸºç¡€æ¨¡å¼**ï¼šé€‚ç”¨äºä¸€èˆ¬æ€§é—®é¢˜ï¼Œæä¾›å¸¸è§„å›ç­”

#### 5.1.2 ç±»ç»“æ„è®¾è®¡

```python
class GenerationIntegrationModule:
    """ç”Ÿæˆé›†æˆæ¨¡å— - è´Ÿè´£LLMé›†æˆå’Œå›ç­”ç”Ÿæˆ"""
    
    def __init__(self, model_name: str = "kimi-k2-0711-preview", 
                 temperature: float = 0.1, max_tokens: int = 2048):
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.llm = None
        self.setup_llm()
```

- `temperature`: ç”Ÿæˆæ¸©åº¦ï¼Œæ§åˆ¶å›ç­”çš„åˆ›é€ æ€§
- `max_tokens`: æœ€å¤§ç”Ÿæˆé•¿åº¦
- `llm`: Moonshot Chatæ¨¡å‹å®ä¾‹

#### 5.1.3 æŸ¥è¯¢è·¯ç”±å®ç°

```python
def query_router(self, query: str) -> str:
    """æŸ¥è¯¢è·¯ç”± - æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹å¼"""
    prompt = ChatPromptTemplate.from_template("""
æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œå°†å…¶åˆ†ç±»ä¸ºä»¥ä¸‹ä¸‰ç§ç±»å‹ä¹‹ä¸€ï¼š

1. 'list' - ç”¨æˆ·æƒ³è¦è·å–èœå“åˆ—è¡¨æˆ–æ¨èï¼Œåªéœ€è¦èœå
   ä¾‹å¦‚ï¼šæ¨èå‡ ä¸ªç´ èœã€æœ‰ä»€ä¹ˆå·èœã€ç»™æˆ‘3ä¸ªç®€å•çš„èœ

2. 'detail' - ç”¨æˆ·æƒ³è¦å…·ä½“çš„åˆ¶ä½œæ–¹æ³•æˆ–è¯¦ç»†ä¿¡æ¯
   ä¾‹å¦‚ï¼šå®«ä¿é¸¡ä¸æ€ä¹ˆåšã€åˆ¶ä½œæ­¥éª¤ã€éœ€è¦ä»€ä¹ˆé£Ÿæ

3. 'general' - å…¶ä»–ä¸€èˆ¬æ€§é—®é¢˜
   ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯å·èœã€åˆ¶ä½œæŠ€å·§ã€è¥å…»ä»·å€¼

è¯·åªè¿”å›åˆ†ç±»ç»“æœï¼šlistã€detail æˆ– general

ç”¨æˆ·é—®é¢˜: {query}

åˆ†ç±»ç»“æœ:""")
    
    # ... (LCELé“¾å¼è°ƒç”¨)
    return result
```

æŸ¥è¯¢è·¯ç”±æ˜¯æ•´ä¸ªç³»ç»Ÿçš„å…³é”®ï¼Œå†³å®šäº†åç»­çš„å¤„ç†æµç¨‹ã€‚é€šè¿‡LLMè‡ªåŠ¨åˆ¤æ–­æŸ¥è¯¢æ„å›¾ï¼Œæ¯”ç®€å•çš„å…³é”®è¯åŒ¹é…æ›´å‡†ç¡®ã€‚

#### 5.1.4 æŸ¥è¯¢é‡å†™ä¼˜åŒ–

```python
def query_rewrite(self, query: str) -> str:
    """æ™ºèƒ½æŸ¥è¯¢é‡å†™ - è®©å¤§æ¨¡å‹åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å†™æŸ¥è¯¢"""
    # ä½¿ç”¨LLMåˆ†ææŸ¥è¯¢æ˜¯å¦éœ€è¦é‡å†™
    # å…·ä½“æ˜ç¡®çš„æŸ¥è¯¢ï¼ˆå¦‚"å®«ä¿é¸¡ä¸æ€ä¹ˆåš"ï¼‰ä¿æŒåŸæ ·
    # æ¨¡ç³ŠæŸ¥è¯¢ï¼ˆå¦‚"åšèœ"ã€"æ¨èä¸ªèœ"ï¼‰è¿›è¡Œé‡å†™ä¼˜åŒ–

    # ... (æç¤ºè¯è®¾è®¡å’ŒLCELé“¾å¼è°ƒç”¨)
    return response
```

æŸ¥è¯¢é‡å†™èƒ½å¤Ÿå°†æ¨¡ç³Šçš„ç”¨æˆ·è¾“å…¥è½¬æ¢ä¸ºæ›´é€‚åˆæ£€ç´¢çš„æŸ¥è¯¢ï¼Œæ˜¾è‘—æå‡ç³»ç»Ÿçš„å®ç”¨æ€§ã€‚é‡å†™è§„åˆ™åŒ…æ‹¬ï¼šä¿æŒåŸæ„ä¸å˜ã€å¢åŠ ç›¸å…³çƒ¹é¥ªæœ¯è¯­ã€ä¼˜å…ˆæ¨èç®€å•æ˜“åšçš„èœå“ã€‚

#### 5.1.5 å¤šæ¨¡å¼ç”Ÿæˆ

**åˆ—è¡¨æ¨¡å¼ç”Ÿæˆ**ï¼š

```python
def generate_list_answer(self, query: str, context_docs: List[Document]) -> str:
    """ç”Ÿæˆåˆ—è¡¨å¼å›ç­” - é€‚ç”¨äºæ¨èç±»æŸ¥è¯¢"""
    # æå–èœå“åç§°
    dish_names = []
    for doc in context_docs:
        dish_name = doc.metadata.get('dish_name', 'æœªçŸ¥èœå“')
        if dish_name not in dish_names:
            dish_names.append(dish_name)
    
    # æ„å»ºç®€æ´çš„åˆ—è¡¨å›ç­”
    if len(dish_names) <= 3:
        return f"ä¸ºæ‚¨æ¨èä»¥ä¸‹èœå“ï¼š\n" + "\n".join([f"{i+1}. {name}" for i, name in enumerate(dish_names)])
    # ... (å…¶ä»–æƒ…å†µå¤„ç†)
```

**è¯¦ç»†æ¨¡å¼ç”Ÿæˆ**ï¼š

```python
def generate_step_by_step_answer(self, query: str, context_docs: List[Document]) -> str:
    """ç”Ÿæˆåˆ†æ­¥éª¤å›ç­”"""
    # ä½¿ç”¨ç»“æ„åŒ–æç¤ºè¯ï¼ŒåŒ…å«ï¼š
    # - ğŸ¥˜ èœå“ä»‹ç»
    # - ğŸ›’ æ‰€éœ€é£Ÿæ
    # - ğŸ‘¨â€ğŸ³ åˆ¶ä½œæ­¥éª¤
    # - ğŸ’¡ åˆ¶ä½œæŠ€å·§

    # ... (æç¤ºè¯è®¾è®¡å’ŒLCELé“¾å¼è°ƒç”¨)
    return response
```

è¯¦ç»†æ¨¡å¼ä½¿ç”¨ç»“æ„åŒ–çš„æç¤ºè¯è®¾è®¡ï¼Œè®©LLMèƒ½å¤Ÿç”Ÿæˆæ ¼å¼è§„èŒƒã€å†…å®¹ä¸°å¯Œçš„åˆ†æ­¥éª¤æŒ‡å¯¼ï¼Œé‡ç‚¹çªå‡ºå®ç”¨æ€§å’Œå¯æ“ä½œæ€§ã€‚



#### 5.2 ç³»ç»Ÿæ•´åˆ

ä¸»ç¨‹åºè´Ÿè´£åè°ƒå„ä¸ªæ¨¡å—ï¼Œå®ç°å®Œæ•´çš„RAGæµç¨‹ï¼šæ•°æ®å‡†å¤‡ â†’ ç´¢å¼•æ„å»º â†’ æ£€ç´¢ä¼˜åŒ– â†’ ç”Ÿæˆé›†æˆã€‚åŒæ—¶æä¾›äº†ç´¢å¼•ç¼“å­˜ã€äº¤äº’å¼é—®ç­”ç­‰å®ç”¨åŠŸèƒ½ã€‚

#### 5.2.1 ä¸»ç³»ç»Ÿç±»è®¾è®¡

```python
class RecipeRAGSystem:
    """é£Ÿè°±RAGç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, config: RAGConfig = None):
        self.config = config or DEFAULT_CONFIG
        self.data_module = None
        self.index_module = None
        self.retrieval_module = None
        self.generation_module = None
        
        # æ£€æŸ¥æ•°æ®è·¯å¾„å’ŒAPIå¯†é’¥
        if not Path(self.config.data_path).exists():
            raise FileNotFoundError(f"æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {self.config.data_path}")
        if not os.getenv("MOONSHOT_API_KEY"):
            raise ValueError("è¯·è®¾ç½® MOONSHOT_API_KEY ç¯å¢ƒå˜é‡")
```

ä¸»ç³»ç»Ÿç±»è´Ÿè´£åè°ƒæ‰€æœ‰æ¨¡å—ï¼Œç¡®ä¿ç³»ç»Ÿçš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§ã€‚

#### 5.2.2 ç³»ç»Ÿåˆå§‹åŒ–æµç¨‹

```python
def initialize_system(self):
    """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—"""
    # 1. åˆå§‹åŒ–æ•°æ®å‡†å¤‡æ¨¡å—
    self.data_module = DataPreparationModule(self.config.data_path)
    
    # 2. åˆå§‹åŒ–ç´¢å¼•æ„å»ºæ¨¡å—
    self.index_module = IndexConstructionModule(
        model_name=self.config.embedding_model,
        index_save_path=self.config.index_save_path
    )
    
    # 3. åˆå§‹åŒ–ç”Ÿæˆé›†æˆæ¨¡å—
    self.generation_module = GenerationIntegrationModule(
        model_name=self.config.llm_model,
        temperature=self.config.temperature,
        max_tokens=self.config.max_tokens
    )
```

åˆå§‹åŒ–è¿‡ç¨‹æŒ‰ç…§ä¾èµ–å…³ç³»æœ‰åºè¿›è¡Œï¼Œä¿è¯æ¯ä¸ªæ¨¡å—éƒ½èƒ½æ­£ç¡®è®¾ç½®ã€‚

#### 5.2.3 çŸ¥è¯†åº“æ„å»ºæµç¨‹

```python
def build_knowledge_base(self):
    """æ„å»ºçŸ¥è¯†åº“"""
    # 1. å°è¯•åŠ è½½å·²ä¿å­˜çš„ç´¢å¼•
    vectorstore = self.index_module.load_index()
    
    if vectorstore is not None:
        # åŠ è½½å·²æœ‰ç´¢å¼•ï¼Œä½†ä»éœ€è¦æ–‡æ¡£å’Œåˆ†å—ç”¨äºæ£€ç´¢æ¨¡å—
        self.data_module.load_documents()
        chunks = self.data_module.chunk_documents()
    else:
        # æ„å»ºæ–°ç´¢å¼•çš„å®Œæ•´æµç¨‹
        self.data_module.load_documents()
        chunks = self.data_module.chunk_documents()
        vectorstore = self.index_module.build_vector_index(chunks)
        self.index_module.save_index()
    
    # åˆå§‹åŒ–æ£€ç´¢ä¼˜åŒ–æ¨¡å—
    self.retrieval_module = RetrievalOptimizationModule(vectorstore, chunks)
```

è¿™ä¸ªæµç¨‹è¿ç”¨äº†ä¹‹å‰è®¾è®¡çš„ç´¢å¼•ç¼“å­˜æœºåˆ¶ï¼Œèƒ½å¤Ÿå¤§å¹…æå‡ç³»ç»Ÿå¯åŠ¨é€Ÿåº¦ã€‚

#### 5.2.4 æ™ºèƒ½é—®ç­”æµç¨‹

```python
def ask_question(self, question: str, stream: bool = False):
    """å›ç­”ç”¨æˆ·é—®é¢˜"""
    # 1. æŸ¥è¯¢è·¯ç”±
    route_type = self.generation_module.query_router(question)

    # 2. æ™ºèƒ½æŸ¥è¯¢é‡å†™ï¼ˆæ ¹æ®è·¯ç”±ç±»å‹ï¼‰
    if route_type == 'list':
        rewritten_query = question  # åˆ—è¡¨æŸ¥è¯¢ä¿æŒåŸæ ·
    else:
        rewritten_query = self.generation_module.query_rewrite(question)

    # 3. æ£€ç´¢ç›¸å…³å­å—
    relevant_chunks = self.retrieval_module.hybrid_search(rewritten_query, top_k=self.config.top_k)

    # 4. æ ¹æ®è·¯ç”±ç±»å‹é€‰æ‹©å›ç­”æ–¹å¼
    if route_type == 'list':
        # åˆ—è¡¨æŸ¥è¯¢ï¼šè¿”å›èœå“åç§°åˆ—è¡¨
        relevant_docs = self.data_module.get_parent_documents(relevant_chunks)
        return self.generation_module.generate_list_answer(question, relevant_docs)
    else:
        # è¯¦ç»†æŸ¥è¯¢ï¼šè·å–å®Œæ•´æ–‡æ¡£å¹¶ç”Ÿæˆè¯¦ç»†å›ç­”
        relevant_docs = self.data_module.get_parent_documents(relevant_chunks)

        if route_type == "detail":
            # è¯¦ç»†æŸ¥è¯¢ä½¿ç”¨åˆ†æ­¥æŒ‡å¯¼æ¨¡å¼
            return self.generation_module.generate_step_by_step_answer(question, relevant_docs)
        else:
            # ä¸€èˆ¬æŸ¥è¯¢ä½¿ç”¨åŸºç¡€å›ç­”æ¨¡å¼
            return self.generation_module.generate_basic_answer(question, relevant_docs)
```

è¿™éƒ¨åˆ†å±•ç¤ºäº†ç¨‹åºæ‰§è¡Œæµç¨‹ï¼šæ™ºèƒ½è·¯ç”± â†’ æŸ¥è¯¢ä¼˜åŒ– â†’ æ··åˆæ£€ç´¢ â†’ çˆ¶å­æ–‡æ¡£å¤„ç† â†’ å¤šæ¨¡å¼ç”Ÿæˆã€‚

