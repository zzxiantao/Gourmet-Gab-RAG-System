#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æ‰¹å¤„ç†ç®¡ç†å™¨ - ç®¡ç†èœè°±å¤„ç†çš„åˆ†æ‰¹ä¿å­˜å’Œæ–­ç‚¹ç»­ä¼ åŠŸèƒ½
"""

import os
import json
import sys
import argparse
from datetime import datetime
from recipe_ai_agent import KimiRecipeAgent, RecipeKnowledgeGraphBuilder

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_file = "config.json"
    if os.path.exists(config_file):
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        print("âŒ æœªæ‰¾åˆ°config.jsoné…ç½®æ–‡ä»¶")
        sys.exit(1)

def show_progress_status(output_dir: str):
    """æ˜¾ç¤ºå¤„ç†è¿›åº¦çŠ¶æ€"""
    progress_file = os.path.join(output_dir, "progress.json")
    
    if not os.path.exists(progress_file):
        print("ğŸ“‹ æœªæ‰¾åˆ°è¿›åº¦æ–‡ä»¶ï¼Œæ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡")
        return
    
    try:
        with open(progress_file, 'r', encoding='utf-8') as f:
            progress_data = json.load(f)
        
        print("å¤„ç†è¿›åº¦çŠ¶æ€:")
        print(f"æ€»æ–‡ä»¶: {progress_data.get('total_files', 'N/A')}, å·²å¤„ç†: {progress_data.get('processed_count', 0)}")

        status = progress_data.get('current_file', 'N/A')
        if status == 'COMPLETED':
            print("çŠ¶æ€: å·²å®Œæˆ")
        elif status == 'INTERRUPTED':
            print("çŠ¶æ€: è¢«ä¸­æ–­")
        else:
            print("çŠ¶æ€: è¿›è¡Œä¸­")
            
        # æ£€æŸ¥æ‰¹æ¬¡æ–‡ä»¶
        batch_dirs = [d for d in os.listdir(output_dir) 
                     if d.startswith("batch_") and os.path.isdir(os.path.join(output_dir, d))]
        
        if batch_dirs:
            print(f"å·²ä¿å­˜æ‰¹æ¬¡: {len(batch_dirs)} ä¸ª")
        
    except Exception as e:
        print(f"âŒ è¯»å–è¿›åº¦æ–‡ä»¶å¤±è´¥: {str(e)}")

def clean_progress(output_dir: str):
    """æ¸…ç†è¿›åº¦æ–‡ä»¶ï¼Œé‡æ–°å¼€å§‹å¤„ç†"""
    progress_file = os.path.join(output_dir, "progress.json")
    
    if os.path.exists(progress_file):
        confirm = input("âš ï¸  ç¡®è®¤è¦æ¸…ç†è¿›åº¦æ–‡ä»¶å—ï¼Ÿè¿™å°†åˆ é™¤æ‰€æœ‰å¤„ç†è¿›åº¦ (y/N): ").strip().lower()
        if confirm == 'y':
            os.remove(progress_file)
            print("âœ… è¿›åº¦æ–‡ä»¶å·²æ¸…ç†")
        else:
            print("å–æ¶ˆæ“ä½œ")
    else:
        print("ğŸ“‹ æœªæ‰¾åˆ°è¿›åº¦æ–‡ä»¶")

def clean_batches(output_dir: str):
    """æ¸…ç†æ‰€æœ‰æ‰¹æ¬¡æ•°æ®"""
    batch_dirs = [d for d in os.listdir(output_dir) 
                 if d.startswith("batch_") and os.path.isdir(os.path.join(output_dir, d))]
    
    if not batch_dirs:
        print("ğŸ“ æœªæ‰¾åˆ°æ‰¹æ¬¡æ•°æ®")
        return
    
    print(f"æ‰¾åˆ° {len(batch_dirs)} ä¸ªæ‰¹æ¬¡ç›®å½•:")
    for batch_dir in sorted(batch_dirs):
        print(f"   - {batch_dir}")
    
    confirm = input("\nâš ï¸  ç¡®è®¤è¦åˆ é™¤æ‰€æœ‰æ‰¹æ¬¡æ•°æ®å—ï¼Ÿ (y/N): ").strip().lower()
    if confirm == 'y':
        import shutil
        for batch_dir in batch_dirs:
            batch_path = os.path.join(output_dir, batch_dir)
            shutil.rmtree(batch_path)
            print(f"ğŸ—‘ï¸  å·²åˆ é™¤: {batch_dir}")
        print("âœ… æ‰€æœ‰æ‰¹æ¬¡æ•°æ®å·²æ¸…ç†")
    else:
        print("å–æ¶ˆæ“ä½œ")

def merge_batches(output_dir: str):
    """æ‰‹åŠ¨åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡æ•°æ®"""
    config = load_config()
    api_key = config["kimi"].get("api_key")
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥é…ç½®")
        return
    
    try:
        ai_agent = KimiRecipeAgent(api_key)
        builder = RecipeKnowledgeGraphBuilder(ai_agent, output_dir)
        
        print("åˆå¹¶æ‰¹æ¬¡æ•°æ®...")
        total_concepts, total_relationships = builder.merge_all_batches()

        if total_concepts > 0 or total_relationships > 0:
            print(f"åˆå¹¶å®Œæˆ: {total_concepts} æ¦‚å¿µ, {total_relationships} å…³ç³»")

            # ç”ŸæˆNeo4jæ ¼å¼
            format_type = config["output"].get("format", "neo4j")
            if format_type == "neo4j":
                builder.export_to_neo4j_csv(output_dir, merge_batches=False)
        else:
            print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ‰¹æ¬¡æ•°æ®")
            
    except Exception as e:
        print(f"âŒ åˆå¹¶å¤±è´¥: {str(e)}")

def continue_processing(recipe_dir: str, output_dir: str):
    """ç»§ç»­å¤„ç†ä¸­æ–­çš„ä»»åŠ¡"""
    config = load_config()
    api_key = config["kimi"].get("api_key")
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°APIå¯†é’¥é…ç½®")
        return
    
    try:
        ai_agent = KimiRecipeAgent(api_key)
        batch_size = config.get("processing", {}).get("batch_size", 20)
        builder = RecipeKnowledgeGraphBuilder(ai_agent, output_dir, batch_size)
        
        print("ç»§ç»­å¤„ç†ä¸­æ–­çš„ä»»åŠ¡...")
        processed, failed = builder.batch_process_recipes(recipe_dir, resume=True)

        print(f"å¤„ç†å®Œæˆ: æ€»æ•° {processed}, å¤±è´¥ {failed}")

        # è‡ªåŠ¨åˆå¹¶æ•°æ®
        print("è‡ªåŠ¨åˆå¹¶æ‰¹æ¬¡æ•°æ®...")
        merge_batches(output_dir)
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")

def show_batch_details(output_dir: str, batch_num: int = None):
    """æ˜¾ç¤ºæ‰¹æ¬¡è¯¦ç»†ä¿¡æ¯"""
    batch_dirs = [d for d in os.listdir(output_dir) 
                 if d.startswith("batch_") and os.path.isdir(os.path.join(output_dir, d))]
    
    if not batch_dirs:
        print("ğŸ“ æœªæ‰¾åˆ°æ‰¹æ¬¡æ•°æ®")
        return
    
    batch_dirs.sort()
    
    if batch_num is not None:
        target_batch = f"batch_{batch_num:03d}"
        if target_batch not in batch_dirs:
            print(f"âŒ æœªæ‰¾åˆ°æ‰¹æ¬¡ {batch_num}")
            return
        batch_dirs = [target_batch]
    
    import pandas as pd
    
    for batch_dir in batch_dirs:
        print(f"\nğŸ“ {batch_dir}:")
        batch_path = os.path.join(output_dir, batch_dir)
        
        # æ¦‚å¿µæ–‡ä»¶
        concepts_file = os.path.join(batch_path, "concepts.csv")
        if os.path.exists(concepts_file):
            df = pd.read_csv(concepts_file)
            print(f"   æ¦‚å¿µæ•°é‡: {len(df)}")
            
            # æŒ‰ç±»å‹ç»Ÿè®¡
            if 'concept_type' in df.columns:
                type_counts = df['concept_type'].value_counts()
                for concept_type, count in type_counts.items():
                    print(f"     - {concept_type}: {count}")
        
        # å…³ç³»æ–‡ä»¶
        relationships_file = os.path.join(batch_path, "relationships.csv")
        if os.path.exists(relationships_file):
            df = pd.read_csv(relationships_file)
            print(f"   å…³ç³»æ•°é‡: {len(df)}")
            
            # æŒ‰ç±»å‹ç»Ÿè®¡
            if 'relationship_type' in df.columns:
                type_counts = df['relationship_type'].value_counts()
                for rel_type, count in type_counts.items():
                    print(f"     - {rel_type}: {count}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='åˆ†æ‰¹å¤„ç†ç®¡ç†å™¨ - ç®¡ç†èœè°±å¤„ç†çš„åˆ†æ‰¹ä¿å­˜å’Œæ–­ç‚¹ç»­ä¼ ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python batch_manager.py status                    # æŸ¥çœ‹å¤„ç†çŠ¶æ€
  python batch_manager.py continue ./HowToCook-master  # ç»§ç»­ä¸­æ–­çš„å¤„ç†
  python batch_manager.py merge                     # åˆå¹¶æ‰¹æ¬¡æ•°æ®
  python batch_manager.py clean-progress            # æ¸…ç†è¿›åº¦æ–‡ä»¶
  python batch_manager.py clean-batches             # æ¸…ç†æ‰¹æ¬¡æ•°æ®
  python batch_manager.py details                   # æ˜¾ç¤ºæ‰€æœ‰æ‰¹æ¬¡è¯¦æƒ…
  python batch_manager.py details -b 1              # æ˜¾ç¤ºæŒ‡å®šæ‰¹æ¬¡è¯¦æƒ…
        """)
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # statuså‘½ä»¤
    subparsers.add_parser('status', help='æŸ¥çœ‹å¤„ç†è¿›åº¦çŠ¶æ€')
    
    # continueå‘½ä»¤
    continue_parser = subparsers.add_parser('continue', help='ç»§ç»­ä¸­æ–­çš„å¤„ç†')
    continue_parser.add_argument('recipe_dir', help='èœè°±ç›®å½•è·¯å¾„')
    
    # mergeå‘½ä»¤
    subparsers.add_parser('merge', help='åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡æ•°æ®')
    
    # cleanå‘½ä»¤
    subparsers.add_parser('clean-progress', help='æ¸…ç†è¿›åº¦æ–‡ä»¶')
    subparsers.add_parser('clean-batches', help='æ¸…ç†æ‰€æœ‰æ‰¹æ¬¡æ•°æ®')
    
    # detailså‘½ä»¤
    details_parser = subparsers.add_parser('details', help='æ˜¾ç¤ºæ‰¹æ¬¡è¯¦ç»†ä¿¡æ¯')
    details_parser.add_argument('-b', '--batch', type=int, help='æŒ‡å®šæ‰¹æ¬¡ç¼–å·')
    
    # å…¨å±€å‚æ•°
    parser.add_argument('-o', '--output', default='./ai_output', help='è¾“å‡ºç›®å½•è·¯å¾„')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(args.output, exist_ok=True)
    
    print("ğŸ› ï¸  åˆ†æ‰¹å¤„ç†ç®¡ç†å™¨")
    print("=" * 50)
    
    try:
        if args.command == 'status':
            show_progress_status(args.output)
        elif args.command == 'continue':
            continue_processing(args.recipe_dir, args.output)
        elif args.command == 'merge':
            merge_batches(args.output)
        elif args.command == 'clean-progress':
            clean_progress(args.output)
        elif args.command == 'clean-batches':
            clean_batches(args.output)
        elif args.command == 'details':
            show_batch_details(args.output, args.batch)
            
    except KeyboardInterrupt:
        print(f"\n\nâ¹ï¸  æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ“ä½œå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main() 