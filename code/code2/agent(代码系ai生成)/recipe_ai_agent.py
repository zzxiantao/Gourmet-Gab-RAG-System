#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºKimi APIçš„æ™ºèƒ½èœè°±è§£æAI Agent
"""

import os
import json
import re
import time
from openai import OpenAI
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
import pandas as pd
import csv
from datetime import datetime

@dataclass
class IngredientInfo:
    """é£Ÿæä¿¡æ¯"""
    name: str
    amount: str = ""
    unit: str = ""
    category: str = ""
    is_main: bool = True  # æ˜¯å¦ä¸»è¦é£Ÿæ
    
@dataclass
class CookingStep:
    """çƒ¹é¥ªæ­¥éª¤"""
    step_number: int
    description: str
    methods: List[str]  # ä½¿ç”¨çš„çƒ¹é¥ªæ–¹æ³•
    tools: List[str]    # éœ€è¦çš„å·¥å…·
    time_estimate: str = ""  # æ—¶é—´ä¼°è®¡
    
@dataclass
class RecipeInfo:
    """èœè°±ä¿¡æ¯"""
    name: str
    difficulty: int  # 1-5æ˜Ÿ
    category: str
    cuisine_type: str = ""  # èœç³»
    prep_time: str = ""
    cook_time: str = ""
    servings: str = ""
    ingredients: List[IngredientInfo] = None
    steps: List[CookingStep] = None
    tags: List[str] = None
    nutrition_info: Dict = None
    
    def __post_init__(self):
        if self.ingredients is None:
            self.ingredients = []
        if self.steps is None:
            self.steps = []
        if self.tags is None:
            self.tags = []
        if self.nutrition_info is None:
            self.nutrition_info = {}

class KimiRecipeAgent:
    """Kimièœè°±è§£æAI Agent"""
    
    def __init__(self, api_key: str, base_url: str = "https://api.moonshot.cn/v1"):
        self.api_key = api_key
        self.base_url = base_url
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        
        # ç›®å½•ååˆ°åˆ†ç±»çš„æ˜ å°„
        self.directory_category_mapping = {
            "vegetable_dish": "ç´ èœ",
            "meat_dish": "è¤èœ", 
            "aquatic": "æ°´äº§",
            "breakfast": "æ—©é¤",
            "staple": "ä¸»é£Ÿ",
            "soup": "æ±¤ç±»",
            "dessert": "ç”œå“",
            "drink": "é¥®æ–™",
            "condiment": "è°ƒæ–™",
            "semi-finished": "åŠæˆå“"
        }
        
        # æ’é™¤çš„ç›®å½•
        self.excluded_directories = ["template", ".github", "tips", "starsystem"]
        
        # é¢„å®šä¹‰çš„é£Ÿæåˆ†ç±»
        self.ingredient_categories = {
            "è”¬èœ": ["èŒ„å­", "è¾£æ¤’", "æ´‹è‘±", "å¤§è‘±", "è¥¿çº¢æŸ¿", "åœŸè±†", "èåœ", "ç™½èœ", "è±†è…"],
            "è°ƒæ–™": ["ç›", "é…±æ²¹", "é†‹", "ç³–", "æ–™é…’", "ç”ŸæŠ½", "è€æŠ½", "èšæ²¹", "å‘³ç²¾"],
            "è›‹ç™½è´¨": ["é¸¡è›‹", "è‚‰", "é±¼", "è™¾", "é¸¡", "çŒª", "ç‰›", "ç¾Š"],
            "æ·€ç²‰ç±»": ["é¢ç²‰", "æ·€ç²‰", "ç±³", "é¢æ¡", "é¢åŒ…", "åœŸè±†"]
        }
        
        # é¢„å®šä¹‰çš„çƒ¹é¥ªæ–¹æ³•
        self.cooking_methods = ["ç‚’", "ç‚¸", "ç…®", "è’¸", "çƒ¤", "ç‚–", "ç„–", "ç…", "çº¢çƒ§", "æ¸…ç‚’", "çˆ†ç‚’"]
        
        # é¢„å®šä¹‰çš„å·¥å…·
        self.cooking_tools = ["ç‚’é”…", "å¹³åº•é”…", "è’¸é”…", "åˆ€", "æ¡ˆæ¿", "ç­·å­", "é”…é“²", "å‹ºå­"]
    
    def call_kimi_api(self, messages: List[Dict], max_retries: int = 3) -> str:
        """è°ƒç”¨Kimi API"""
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model="kimi-k2-0711-preview",
                    messages=messages,
                    temperature=0.3,
                    max_tokens=2048,
                    stream=False
                )
                
                return response.choices[0].message.content
                    
            except Exception as e:
                print(f"APIè°ƒç”¨é”™è¯¯ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    
        raise Exception("Kimi APIè°ƒç”¨å¤±è´¥")
    
    def infer_category_from_path(self, file_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶è·¯å¾„æ¨æ–­èœè°±åˆ†ç±»"""
        path_parts = file_path.replace('\\', '/').split('/')
        
        for part in path_parts:
            if part in self.directory_category_mapping:
                return self.directory_category_mapping[part]
        
        return ""  # å¦‚æœæ— æ³•æ¨æ–­ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
    
    def extract_recipe_info(self, markdown_content: str, file_path: str = "") -> RecipeInfo:
        """ä½¿ç”¨AIæå–èœè°±ä¿¡æ¯"""
        
        # æ ¹æ®è·¯å¾„æ¨æ–­åˆ†ç±»
        inferred_category = self.infer_category_from_path(file_path)
        
        # æ„å»ºæç¤ºè¯
        category_hint = f"ï¼Œæ ¹æ®æ–‡ä»¶è·¯å¾„æ¨æ–­æ­¤èœè°±å±äºã€{inferred_category}ã€‘åˆ†ç±»" if inferred_category else ""
        
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ ‡å‡†åŒ–æ ¼å¼çš„èœè°±Markdownæ–‡æ¡£ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯å¹¶ä»¥JSONæ ¼å¼è¿”å›ã€‚

æ–‡ä»¶è·¯å¾„: {file_path}
èœè°±å†…å®¹ï¼š
{markdown_content}

## æ–‡æ¡£ç»“æ„è¯´æ˜
æ­¤èœè°±éµå¾ªæ ‡å‡†æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å›ºå®šäºŒçº§æ ‡é¢˜ï¼š
- ## å¿…å¤‡åŸæ–™å’Œå·¥å…·ï¼šåˆ—å‡ºæ‰€æœ‰é£Ÿæå’Œå·¥å…·
- ## è®¡ç®—ï¼šåŒ…å«ä»½é‡è®¡ç®—å’Œå…·ä½“ç”¨é‡
- ## æ“ä½œï¼šè¯¦ç»†çš„çƒ¹é¥ªæ­¥éª¤
- ## é™„åŠ å†…å®¹ï¼šè¡¥å……è¯´æ˜å’ŒæŠ€å·§æç¤ºï¼ˆéœ€è¦è¿‡æ»¤æ— å…³å†…å®¹ï¼‰

## æå–è§„åˆ™
1. **èœè°±åç§°**ï¼šä»ä¸€çº§æ ‡é¢˜ï¼ˆ# XXXçš„åšæ³•ï¼‰æå–
2. **éš¾åº¦ç­‰çº§**ï¼šä»"é¢„ä¼°çƒ¹é¥ªéš¾åº¦ï¼šâ˜…â˜…â˜…"ä¸­ç»Ÿè®¡â˜…çš„æ•°é‡
3. **èœè°±åˆ†ç±»**ï¼šå¯ä»¥æ˜¯å¤šä¸ªåˆ†ç±»ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¦‚"æ—©é¤,ç´ èœ"è¡¨ç¤ºæ—¢æ˜¯æ—©é¤åˆæ˜¯ç´ èœï¼‰
4. **é£Ÿæä¿¡æ¯**ï¼šä»"å¿…å¤‡åŸæ–™å’Œå·¥å…·"å’Œ"è®¡ç®—"éƒ¨åˆ†æå–ï¼Œåˆå¹¶ç”¨é‡ä¿¡æ¯
5. **çƒ¹é¥ªæ­¥éª¤**ï¼šä»"æ“ä½œ"éƒ¨åˆ†çš„æœ‰åºåˆ—è¡¨æå–
6. **æŠ€å·§è¡¥å……**ï¼šä»"é™„åŠ å†…å®¹"æå–æœ‰ç”¨çš„çƒ¹é¥ªæŠ€å·§ï¼Œå¿½ç•¥æ¨¡æ¿æ–‡å­—ï¼ˆå¦‚"å¦‚æœæ‚¨éµå¾ªæœ¬æŒ‡å—...Issueæˆ–Pull request"ç­‰ï¼‰

è¯·è¿”å›æ ‡å‡†JSONæ ¼å¼{category_hint}ï¼š
{{
    "name": "èœè°±åç§°ï¼ˆå»æ‰'çš„åšæ³•'åç¼€ï¼‰",
    "difficulty": 1-5çš„æ•°å­—ï¼ˆæ ¹æ®â˜…æ•°é‡ï¼šâ˜…=1, â˜…â˜…=2, â˜…â˜…â˜…=3, â˜…â˜…â˜…â˜…=4, â˜…â˜…â˜…â˜…â˜…=5ï¼‰ï¼Œ
    "category": "{inferred_category if inferred_category else 'èœè°±åˆ†ç±»ï¼ˆç´ èœ/è¤èœ/æ°´äº§/æ—©é¤/ä¸»é£Ÿ/æ±¤ç±»/ç”œå“/é¥®æ–™/è°ƒæ–™ï¼Œæ”¯æŒå¤šä¸ªåˆ†ç±»ç”¨é€—å·åˆ†éš”ï¼Œå¦‚\"æ—©é¤,ç´ èœ\"ï¼‰'}",
    "cuisine_type": "èœç³»ï¼ˆå·èœ/ç²¤èœ/é²èœ/è‹èœ/é—½èœ/æµ™èœ/æ¹˜èœ/å¾½èœ/ä¸œåŒ—èœ/è¥¿åŒ—èœ/ç­‰ï¼Œå¦‚æœä¸æ˜ç¡®åˆ™ä¸ºç©ºï¼‰",
    "prep_time": "å‡†å¤‡æ—¶é—´ï¼ˆä»è…Œåˆ¶ã€åˆ‡èœç­‰æ­¥éª¤æ¨æ–­ï¼‰",
    "cook_time": "çƒ¹é¥ªæ—¶é—´ï¼ˆä»ç‚’åˆ¶ã€ç‚–ç…®ç­‰æ­¥éª¤æ¨æ–­ï¼‰", 
    "servings": "ä»½æ•°/äººæ•°ï¼ˆä»'è®¡ç®—'éƒ¨åˆ†æå–ï¼Œå¦‚'2ä¸ªäººé£Ÿç”¨'ï¼‰",
    "ingredients": [
        {{
            "name": "é£Ÿæåç§°",
            "amount": "ç”¨é‡æ•°å­—ï¼ˆä»è®¡ç®—éƒ¨åˆ†æå–å…·ä½“æ•°å€¼ï¼‰",
            "unit": "å•ä½ï¼ˆå…‹ã€ä¸ªã€æ¯«å‡ã€ç‰‡ç­‰ï¼‰",
            "category": "é£Ÿæç±»åˆ«ï¼ˆè”¬èœ/è°ƒæ–™/è›‹ç™½è´¨/æ·€ç²‰ç±»/å…¶ä»–ï¼‰",
            "is_main": true/falseï¼ˆä¸»è¦é£Ÿæä¸ºtrueï¼Œè°ƒæ–™ä¸ºfalseï¼‰
        }}
    ],
    "steps": [
        {{
            "step_number": 1,
            "description": "æ­¥éª¤è¯¦ç»†æè¿°",
            "methods": ["ä½¿ç”¨çš„çƒ¹é¥ªæ–¹æ³•ï¼šç‚’ã€ç‚¸ã€ç…®ã€è’¸ã€çƒ¤ã€ç‚–ã€ç„–ã€ç…ã€çº¢çƒ§ã€è…Œåˆ¶ã€åˆ‡ç­‰"],
            "tools": ["éœ€è¦çš„å·¥å…·ï¼šç‚’é”…ã€å¹³åº•é”…ã€è’¸é”…ã€åˆ€ã€æ¡ˆæ¿ã€ç­·å­ã€é”…é“²ã€ç›†ç­‰"],
            "time_estimate": "æ—¶é—´ä¼°è®¡ï¼ˆå¦‚æ­¥éª¤ä¸­æåˆ°'15ç§’'ã€'30ç§’'ã€'10-15åˆ†é’Ÿ'ç­‰ï¼‰"
        }}
    ],
    "tags": ["ä»é™„åŠ å†…å®¹ä¸­æå–çš„æœ‰ç”¨æŠ€å·§æ ‡ç­¾"],
    "nutrition_info": {{
        "calories": "",
        "protein": "", 
        "carbs": "",
        "fat": ""
    }}
}}

## é‡è¦æç¤ºï¼š
1. ä»"è®¡ç®—"éƒ¨åˆ†ç²¾ç¡®æå–é£Ÿæç”¨é‡å’Œå•ä½
2. ä»"æ“ä½œ"éƒ¨åˆ†çš„æœ‰åºåˆ—è¡¨é€æ­¥è§£æçƒ¹é¥ªæ­¥éª¤
3. ä»"é™„åŠ å†…å®¹"ä¸­åªæå–çƒ¹é¥ªæŠ€å·§ï¼Œå¿½ç•¥"Issueæˆ–Pull request"ç­‰æ¨¡æ¿æ–‡å­—
4. é£Ÿæåˆ†ç±»è¦å‡†ç¡®ï¼šè”¬èœï¼ˆåŒ…æ‹¬å„ç§èœç±»ï¼‰ã€è°ƒæ–™ï¼ˆç›ã€é…±æ²¹ã€ç³–ç­‰ï¼‰ã€è›‹ç™½è´¨ï¼ˆé±¼ã€è‚‰ã€è›‹ï¼‰ã€æ·€ç²‰ç±»ï¼ˆé¢ç²‰ã€ç±³ç­‰ï¼‰
5. èœè°±åˆ†ç±»æ”¯æŒå¤šé‡åˆ†ç±»ï¼šå¦‚æ—©é¤ç±»çš„è”¬èœç²¥å¯ä»¥åˆ†ç±»ä¸º"æ—©é¤,ç´ èœ,ä¸»é£Ÿ"ï¼ˆé€—å·åˆ†éš”ï¼‰
6. å½“é‡åˆ°"é€‚é‡"ã€"å°‘è®¸"ç­‰éå…·ä½“æ•°å€¼æ—¶ï¼Œä¸è¦å¿˜è®°åŠ å¼•å·ï¼Œå¦‚"amount": "é€‚é‡"
7. åªè¿”å›æ ‡å‡†JSONæ ¼å¼ï¼Œç¡®ä¿è¯­æ³•æ­£ç¡®
"""

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èœè°±åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»ä¸­æ–‡èœè°±ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        try:
            response = self.call_kimi_api(messages)
            
            # æ¸…ç†å“åº”ï¼Œç¡®ä¿æ˜¯æœ‰æ•ˆçš„JSON
            response = response.strip()
            if response.startswith("```json"):
                response = response[7:]
            if response.endswith("```"):
                response = response[:-3]
            response = response.strip()
            
            # è§£æJSON
            recipe_data = json.loads(response)
            
            # è½¬æ¢ä¸ºRecipeInfoå¯¹è±¡
            recipe_info = RecipeInfo(
                name=recipe_data.get("name", ""),
                difficulty=recipe_data.get("difficulty", 3),
                category=recipe_data.get("category", ""),
                cuisine_type=recipe_data.get("cuisine_type", ""),
                prep_time=recipe_data.get("prep_time", ""),
                cook_time=recipe_data.get("cook_time", ""),
                servings=recipe_data.get("servings", ""),
                nutrition_info=recipe_data.get("nutrition_info", {})
            )
            
            # è½¬æ¢é£Ÿæä¿¡æ¯
            for ing_data in recipe_data.get("ingredients", []):
                ingredient = IngredientInfo(
                    name=ing_data.get("name", ""),
                    amount=ing_data.get("amount", ""),
                    unit=ing_data.get("unit", ""),
                    category=ing_data.get("category", ""),
                    is_main=ing_data.get("is_main", True)
                )
                recipe_info.ingredients.append(ingredient)
            
            # è½¬æ¢æ­¥éª¤ä¿¡æ¯
            for step_data in recipe_data.get("steps", []):
                step = CookingStep(
                    step_number=step_data.get("step_number", 0),
                    description=step_data.get("description", ""),
                    methods=step_data.get("methods", []),
                    tools=step_data.get("tools", []),
                    time_estimate=step_data.get("time_estimate", "")
                )
                recipe_info.steps.append(step)
            
            # æ·»åŠ æ ‡ç­¾
            recipe_info.tags = recipe_data.get("tags", [])
            
            return recipe_info
            
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            print(f"åŸå§‹å“åº”: {response}")
            return self._fallback_parse(markdown_content)
        except Exception as e:
            print(f"AIè§£æé”™è¯¯: {e}")
            return self._fallback_parse(markdown_content)
    
    def _fallback_parse(self, content: str) -> RecipeInfo:
        """å¤‡ç”¨è§£ææ–¹æ³•ï¼ˆåŸºäºè§„åˆ™ï¼‰"""
        lines = content.strip().split('\n')
        
        # æå–èœè°±åç§°
        name = ""
        for line in lines:
            if line.startswith('# '):
                name = line[2:].replace('çš„åšæ³•', '').strip()
                break
        
        # æå–éš¾åº¦
        difficulty = 3  # é»˜è®¤3æ˜Ÿ
        for line in lines:
            if 'â˜…' in line:
                stars = line.count('â˜…')
                difficulty = min(max(stars, 1), 5)
                break
        
        # ç®€å•åˆ†ç±»åˆ¤æ–­
        category = "å…¶ä»–"
        if any(keyword in name for keyword in ["è›‹", "è±†è…"]):
            category = "ç´ èœ"
        elif any(keyword in name for keyword in ["è‚‰", "é¸¡", "é±¼", "è™¾"]):
            category = "è¤èœ"
        
        return RecipeInfo(
            name=name or "æœªçŸ¥èœè°±",
            difficulty=difficulty,
            category=category
        )

class RecipeKnowledgeGraphBuilder:
    """èœè°±çŸ¥è¯†å›¾è°±æ„å»ºå™¨ - æ”¯æŒåˆ†æ‰¹ä¿å­˜å’Œæ–­ç‚¹ç»­ä¼ """
    
    def __init__(self, ai_agent: KimiRecipeAgent, output_dir: str = "./ai_output", batch_size: int = 20):
        self.ai_agent = ai_agent
        self.concepts = []
        self.relationships = []
        self.concept_id_counter = 201000000
        self.output_dir = output_dir
        self.batch_size = batch_size
        self.progress_file = os.path.join(output_dir, "progress.json")
        self.processed_files = set()
        self.current_batch = 0
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–é¢„å®šä¹‰æ¦‚å¿µå’Œå…³ç³»ç±»å‹æ˜ å°„
        self._init_predefined_concepts()
        self._init_relationship_mappings()
    
    def _init_relationship_mappings(self):
        """åˆå§‹åŒ–å…³ç³»ç±»å‹æ˜ å°„"""
        self.relationship_type_mapping = {
            "has_ingredient": "801000001",
            "requires_tool": "801000002", 
            "has_step": "801000003",
            "belongs_to_category": "801000004",
            "has_difficulty": "801000005",
            "uses_method": "801000006",
            "has_amount": "801000007",
            "step_follows": "801000008",
            "serves_people": "801000009",
            "cooking_time": "801000010",
            "prep_time": "801000011"
        }
    
    def _init_predefined_concepts(self):
        """åˆå§‹åŒ–é¢„å®šä¹‰æ¦‚å¿µ"""
        self.predefined_concepts = [
            # æ ¹æ¦‚å¿µ
            {
                "concept_id": "100000000",
                "concept_type": "Root",
                "name": "çƒ¹é¥ªæ¦‚å¿µ",
                "fsn": "çƒ¹é¥ªæ¦‚å¿µ (Culinary Concept)",
                "preferred_term": "çƒ¹é¥ªæ¦‚å¿µ"
            },
            
            # é¡¶çº§æ¦‚å¿µ
            {
                "concept_id": "200000000",
                "concept_type": "Recipe", 
                "name": "èœè°±",
                "fsn": "èœè°± (Recipe)",
                "preferred_term": "èœè°±"
            },
            {
                "concept_id": "300000000",
                "concept_type": "Ingredient",
                "name": "é£Ÿæ", 
                "fsn": "é£Ÿæ (Ingredient)",
                "preferred_term": "é£Ÿæ"
            },
            {
                "concept_id": "400000000",
                "concept_type": "CookingMethod",
                "name": "çƒ¹é¥ªæ–¹æ³•",
                "fsn": "çƒ¹é¥ªæ–¹æ³• (Cooking Method)", 
                "preferred_term": "çƒ¹é¥ªæ–¹æ³•"
            },
            {
                "concept_id": "500000000",
                "concept_type": "CookingTool",
                "name": "çƒ¹é¥ªå·¥å…·",
                "fsn": "çƒ¹é¥ªå·¥å…· (Cooking Tool)",
                "preferred_term": "çƒ¹é¥ªå·¥å…·"
            },
            
            # éš¾åº¦ç­‰çº§
            {
                "concept_id": "610000000",
                "concept_type": "DifficultyLevel",
                "name": "ä¸€æ˜Ÿ",
                "fsn": "ä¸€æ˜Ÿ (One Star)",
                "preferred_term": "ä¸€æ˜Ÿ"
            },
            {
                "concept_id": "620000000", 
                "concept_type": "DifficultyLevel",
                "name": "äºŒæ˜Ÿ",
                "fsn": "äºŒæ˜Ÿ (Two Star)",
                "preferred_term": "äºŒæ˜Ÿ"
            },
            {
                "concept_id": "630000000", 
                "concept_type": "DifficultyLevel",
                "name": "ä¸‰æ˜Ÿ",
                "fsn": "ä¸‰æ˜Ÿ (Three Star)",
                "preferred_term": "ä¸‰æ˜Ÿ"
            },
            {
                "concept_id": "640000000", 
                "concept_type": "DifficultyLevel",
                "name": "å››æ˜Ÿ",
                "fsn": "å››æ˜Ÿ (Four Star)",
                "preferred_term": "å››æ˜Ÿ"
            },
            {
                "concept_id": "650000000", 
                "concept_type": "DifficultyLevel",
                "name": "äº”æ˜Ÿ",
                "fsn": "äº”æ˜Ÿ (Five Star)",
                "preferred_term": "äº”æ˜Ÿ"
            },
            
            # èœè°±åˆ†ç±»
            {
                "concept_id": "710000000",
                "concept_type": "RecipeCategory",
                "name": "ç´ èœ", 
                "fsn": "ç´ èœ (Vegetarian Dish)",
                "preferred_term": "ç´ èœ"
            },
            {
                "concept_id": "720000000",
                "concept_type": "RecipeCategory",
                "name": "è¤èœ", 
                "fsn": "è¤èœ (Meat Dish)",
                "preferred_term": "è¤èœ"
            },
            {
                "concept_id": "730000000",
                "concept_type": "RecipeCategory",
                "name": "æ°´äº§", 
                "fsn": "æ°´äº§ (Aquatic Product)",
                "preferred_term": "æ°´äº§"
            },
            {
                "concept_id": "740000000",
                "concept_type": "RecipeCategory",
                "name": "æ—©é¤", 
                "fsn": "æ—©é¤ (Breakfast)",
                "preferred_term": "æ—©é¤"
            },
            {
                "concept_id": "750000000",
                "concept_type": "RecipeCategory",
                "name": "ä¸»é£Ÿ", 
                "fsn": "ä¸»é£Ÿ (Staple Food)",
                "preferred_term": "ä¸»é£Ÿ"
            },
            {
                "concept_id": "760000000",
                "concept_type": "RecipeCategory",
                "name": "æ±¤ç±»", 
                "fsn": "æ±¤ç±» (Soup)",
                "preferred_term": "æ±¤ç±»"
            },
            {
                "concept_id": "770000000",
                "concept_type": "RecipeCategory",
                "name": "ç”œå“", 
                "fsn": "ç”œå“ (Dessert)",
                "preferred_term": "ç”œå“"
            },
            {
                "concept_id": "780000000",
                "concept_type": "RecipeCategory",
                "name": "é¥®æ–™", 
                "fsn": "é¥®æ–™ (Beverage)",
                "preferred_term": "é¥®æ–™"
            },
            {
                "concept_id": "790000000",
                "concept_type": "RecipeCategory",
                "name": "è°ƒæ–™", 
                "fsn": "è°ƒæ–™ (Condiment)",
                "preferred_term": "è°ƒæ–™"
            }
        ]
    
    def save_progress(self, current_file: str = None, total_files: int = 0, processed_count: int = 0):
        """ä¿å­˜å¤„ç†è¿›åº¦"""
        progress_data = {
            "processed_files": list(self.processed_files),
            "current_file": current_file,
            "total_files": total_files,
            "processed_count": processed_count,
            "current_batch": self.current_batch,
            "concept_id_counter": self.concept_id_counter,
            "timestamp": datetime.now().isoformat(),
            "concepts_count": len(self.concepts),
            "relationships_count": len(self.relationships)
        }
        
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
    
    def load_progress(self) -> Dict:
        """åŠ è½½å¤„ç†è¿›åº¦"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    progress_data = json.load(f)
                
                self.processed_files = set(progress_data.get("processed_files", []))
                self.current_batch = progress_data.get("current_batch", 0)
                self.concept_id_counter = progress_data.get("concept_id_counter", 201000000)
                
                return progress_data
            except Exception as e:
                print(f"è­¦å‘Š: åŠ è½½è¿›åº¦æ–‡ä»¶å¤±è´¥ - {str(e)}")
                return {}
        return {}
    
    def save_batch_data(self, batch_num: int = None):
        """ä¿å­˜å½“å‰æ‰¹æ¬¡æ•°æ®"""
        if batch_num is None:
            batch_num = self.current_batch
            
        batch_output_dir = os.path.join(self.output_dir, f"batch_{batch_num:03d}")
        os.makedirs(batch_output_dir, exist_ok=True)
        
        # ä¿å­˜æ¦‚å¿µæ•°æ®
        if self.concepts:
            concepts_df = pd.DataFrame(self.concepts)
            concepts_file = os.path.join(batch_output_dir, "concepts.csv")
            concepts_df.to_csv(concepts_file, index=False, encoding='utf-8')
        
        # ä¿å­˜å…³ç³»æ•°æ®
        if self.relationships:
            relationships_df = pd.DataFrame(self.relationships)
            relationships_file = os.path.join(batch_output_dir, "relationships.csv")
            relationships_df.to_csv(relationships_file, index=False, encoding='utf-8')
        
        print(f"æ‰¹æ¬¡ {batch_num} å·²ä¿å­˜")
        
        return batch_output_dir
    
    def merge_all_batches(self):
        """åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡æ•°æ®åˆ°æœ€ç»ˆè¾“å‡ºæ–‡ä»¶"""
        print("åˆå¹¶æ‰¹æ¬¡æ•°æ®...")
        
        all_concepts = []
        all_relationships = []
        
        # æ”¶é›†æ‰€æœ‰æ‰¹æ¬¡æ•°æ®
        batch_dirs = [d for d in os.listdir(self.output_dir) 
                     if d.startswith("batch_") and os.path.isdir(os.path.join(self.output_dir, d))]
        batch_dirs.sort()
        
        for batch_dir in batch_dirs:
            batch_path = os.path.join(self.output_dir, batch_dir)
            
            # è¯»å–æ¦‚å¿µæ–‡ä»¶
            concepts_file = os.path.join(batch_path, "concepts.csv")
            if os.path.exists(concepts_file):
                batch_concepts = pd.read_csv(concepts_file)
                all_concepts.append(batch_concepts)
            
            # è¯»å–å…³ç³»æ–‡ä»¶
            relationships_file = os.path.join(batch_path, "relationships.csv")
            if os.path.exists(relationships_file):
                batch_relationships = pd.read_csv(relationships_file)
                all_relationships.append(batch_relationships)
        
        # åˆå¹¶æ•°æ®
        if all_concepts:
            final_concepts = pd.concat(all_concepts, ignore_index=True)
            final_concepts.to_csv(os.path.join(self.output_dir, "concepts.csv"), 
                                index=False, encoding='utf-8')
            print(f"åˆå¹¶æ¦‚å¿µ: {len(final_concepts)} ä¸ª")
        
        if all_relationships:
            final_relationships = pd.concat(all_relationships, ignore_index=True)
            final_relationships.to_csv(os.path.join(self.output_dir, "relationships.csv"), 
                                     index=False, encoding='utf-8')
            print(f"åˆå¹¶å…³ç³»: {len(final_relationships)} ä¸ª")
        
        return len(final_concepts) if all_concepts else 0, len(final_relationships) if all_relationships else 0
    
    def generate_concept_id(self) -> str:
        """ç”Ÿæˆæ–°çš„æ¦‚å¿µID"""
        self.concept_id_counter += 1
        return str(self.concept_id_counter)
    
    def process_recipe(self, markdown_content: str, file_path: str) -> Dict:
        """å¤„ç†å•ä¸ªèœè°±"""
        # å¤„ç†èœè°±
        
        # ä½¿ç”¨AIæå–èœè°±ä¿¡æ¯
        recipe_info = self.ai_agent.extract_recipe_info(markdown_content, file_path)
        
        # ç”Ÿæˆæ¦‚å¿µID
        recipe_id = self.generate_concept_id()
        
        # åˆ›å»ºèœè°±æ¦‚å¿µ
        recipe_concept = {
            "concept_id": recipe_id,
            "concept_type": "Recipe",
            "name": recipe_info.name,
            "fsn": f"{recipe_info.name} (Recipe)",
            "preferred_term": recipe_info.name,
            "synonyms": self._generate_recipe_synonyms(recipe_info.name, recipe_info.category),
            "category": recipe_info.category,
            "difficulty": recipe_info.difficulty,
            "cuisine_type": recipe_info.cuisine_type,
            "prep_time": recipe_info.prep_time,
            "cook_time": recipe_info.cook_time,
            "servings": recipe_info.servings,
            "tags": ",".join(recipe_info.tags),
            "file_path": file_path
        }
        
        self.concepts.append(recipe_concept)
        
        # å¤„ç†é£Ÿæ
        for ingredient in recipe_info.ingredients:
            ing_id = self.generate_concept_id()
            ing_concept = {
                "concept_id": ing_id,
                "concept_type": "Ingredient",
                "name": ingredient.name,
                "fsn": f"{ingredient.name} (Ingredient)",
                "preferred_term": ingredient.name,
                "synonyms": self._generate_ingredient_synonyms(ingredient.name),
                "category": ingredient.category,
                "amount": ingredient.amount,
                "unit": ingredient.unit,
                "is_main": ingredient.is_main
            }
            self.concepts.append(ing_concept)
            
            # æ·»åŠ å…³ç³»ï¼šèœè°±åŒ…å«é£Ÿæ
            self.relationships.append({
                "relationship_id": f"R_{len(self.relationships) + 1:06d}",
                "source_id": recipe_id,
                "target_id": ing_id,
                "relationship_type": self.relationship_type_mapping["has_ingredient"],
                "amount": ingredient.amount,
                "unit": ingredient.unit
            })
        
        # å¤„ç†æ­¥éª¤
        for step in recipe_info.steps:
            step_id = self.generate_concept_id()
            step_concept = {
                "concept_id": step_id,
                "concept_type": "CookingStep",
                "name": f"æ­¥éª¤{step.step_number}",
                "fsn": f"æ­¥éª¤{step.step_number} (Cooking Step)",
                "preferred_term": f"æ­¥éª¤{step.step_number}",
                "description": step.description,
                "step_number": step.step_number,
                "methods": ",".join(step.methods),
                "tools": ",".join(step.tools),
                "time_estimate": step.time_estimate
            }
            self.concepts.append(step_concept)
            
            # æ·»åŠ å…³ç³»ï¼šèœè°±åŒ…å«æ­¥éª¤
            self.relationships.append({
                "relationship_id": f"R_{len(self.relationships) + 1:06d}",
                "source_id": recipe_id,
                "target_id": step_id,
                "relationship_type": self.relationship_type_mapping["has_step"],
                "step_order": step.step_number
            })
        
        # æ·»åŠ åˆ†ç±»å…³ç³» - æ”¯æŒå¤šé‡åˆ†ç±»
        category_mapping = {
            "ç´ èœ": "710000000",
            "è¤èœ": "720000000", 
            "æ°´äº§": "730000000",
            "æ—©é¤": "740000000",
            "ä¸»é£Ÿ": "750000000",
            "æ±¤ç±»": "760000000",
            "ç”œå“": "770000000",
            "é¥®æ–™": "780000000",
            "è°ƒæ–™": "790000000"
        }
        
        # å¤„ç†å¤šé‡åˆ†ç±»ï¼ˆæ”¯æŒé€—å·åˆ†éš”çš„å¤šä¸ªåˆ†ç±»ï¼‰
        categories = [cat.strip() for cat in recipe_info.category.split(',') if cat.strip()]
        
        for category in categories:
            if category in category_mapping:
                self.relationships.append({
                    "relationship_id": f"R_{len(self.relationships) + 1:06d}",
                    "source_id": recipe_id,
                    "target_id": category_mapping[category],
                    "relationship_type": self.relationship_type_mapping["belongs_to_category"]
                })
        
        # æ·»åŠ éš¾åº¦å…³ç³»
        difficulty_mapping = {
            1: "610000000",  # ä¸€æ˜Ÿ
            2: "620000000",  # äºŒæ˜Ÿ
            3: "630000000",  # ä¸‰æ˜Ÿ
            4: "640000000",  # å››æ˜Ÿ
            5: "650000000"   # äº”æ˜Ÿ
        }
        
        if recipe_info.difficulty in difficulty_mapping:
            self.relationships.append({
                "relationship_id": f"R_{len(self.relationships) + 1:06d}",
                "source_id": recipe_id,
                "target_id": difficulty_mapping[recipe_info.difficulty],
                "relationship_type": self.relationship_type_mapping["has_difficulty"]
            })
        
        return recipe_concept
    
    def _generate_recipe_synonyms(self, name: str, category: str) -> List[str]:
        """ç”Ÿæˆèœè°±çš„åŒä¹‰è¯åˆ—è¡¨"""
        synonyms = []
        
        # åŸºäºèœè°±åç§°ç”Ÿæˆå˜ä½“
        if name.endswith("çš„åšæ³•"):
            base_name = name.replace("çš„åšæ³•", "")
            synonyms.extend([
                f"{base_name}åˆ¶ä½œæ–¹æ³•",
                f"{base_name}çƒ¹é¥ªæ–¹æ³•",
                base_name
            ])
        
        # åŸºäºçƒ¹é¥ªæ–¹æ³•ç”Ÿæˆåˆ«åï¼ˆæ³¨æ„ï¼šåªæœ‰çœŸæ­£çš„åŒä¹‰è¯æ‰æ˜ å°„ï¼‰
        cooking_method_mappings = {
            "çº¢çƒ§": ["braised"],                    # çº¢çƒ§ = è‹±æ–‡braised
            "ç³–é†‹": ["sweet and sour"],            # ç³–é†‹ = è‹±æ–‡sweet and sour  
            "æ¸…ç‚’": ["ç‚’åˆ¶", "stir-fried"],        # æ¸…ç‚’ = ç‚’åˆ¶ = è‹±æ–‡stir-fried
            "è’¸": ["æ¸…è’¸", "steamed"],              # è’¸ = æ¸…è’¸ = è‹±æ–‡steamed
            "ç‚–": ["ç…²", "stewed"],                # ç‚– = ç…² = è‹±æ–‡stewed
            "çƒ¤": ["çƒ˜çƒ¤", "roasted", "baked"],    # çƒ¤ = çƒ˜çƒ¤ = è‹±æ–‡roasted/baked
            "ç‚¸": ["æ²¹ç‚¸", "deep-fried"],          # ç‚¸ = æ²¹ç‚¸ = è‹±æ–‡deep-fried
            "ç„–": ["é—·", "braised"],               # ç„– = é—· = æŸç§å½¢å¼çš„braised
            "ç…": ["pan-fried"],                   # ç… = è‹±æ–‡pan-fried
            "çˆ†ç‚’": ["stir-fried"],               # çˆ†ç‚’ = stir-friedçš„ä¸€ç§
            "ç™½åˆ‡": ["boiled"],                    # ç™½åˆ‡ = æ°´ç…®çš„ä¸€ç§
            "æ²¹ç„–": ["oil-braised"]               # æ²¹ç„– = oil-braised
        }
        
        for method, variants in cooking_method_mappings.items():
            if method in name:
                for variant in variants:
                    if variant != method:  # é¿å…é‡å¤
                        synonym = name.replace(method, variant)
                        if synonym != name:
                            synonyms.append(synonym)
        
        # åŸºäºé£Ÿæç”Ÿæˆåˆ«åï¼ˆæå–ä¸»è¦é£Ÿæï¼‰
        ingredient_aliases = {
            "èŒ„å­": ["é’èŒ„å­", "ç´«èŒ„å­", "eggplant"],
            "åœŸè±†": ["é©¬é“ƒè–¯", "æ´‹èŠ‹", "potato"],
            "è¥¿çº¢æŸ¿": ["ç•ªèŒ„", "tomato"],
            "é’æ¤’": ["å½©æ¤’", "ç”œæ¤’", "bell pepper"],
            "è±†è…": ["å«©è±†è…", "è€è±†è…", "tofu"],
            "ç™½èœ": ["å¤§ç™½èœ", "å°ç™½èœ", "cabbage"],
            "èåœ": ["ç™½èåœ", "èƒ¡èåœ", "radish"]
        }
        
        for ingredient, aliases in ingredient_aliases.items():
            if ingredient in name:
                for alias in aliases:
                    if alias != ingredient:
                        synonym = name.replace(ingredient, alias)
                        if synonym != name:
                            synonyms.append(synonym)
        
        # åŸºäºåœ°åŸŸç‰¹è‰²æ·»åŠ åˆ«å
        regional_mappings = {
            "å·å‘³": ["å››å·é£å‘³", "å·èœé£æ ¼"],
            "ç²¤å¼": ["å¹¿ä¸œé£å‘³", "ç²¤èœé£æ ¼"],
            "äº¬å‘³": ["åŒ—äº¬é£å‘³", "äº¬èœé£æ ¼"],
            "æ¹˜å‘³": ["æ¹–å—é£å‘³", "æ¹˜èœé£æ ¼"]
        }
        
        for region, variants in regional_mappings.items():
            if region in name:
                for variant in variants:
                    synonym = name.replace(region, variant)
                    if synonym != name:
                        synonyms.append(synonym)
        
        # å»é‡å¹¶è¿”å›ï¼ŒæŒ‰è¯­è¨€åˆ†ç±»
        unique_synonyms = list(set(synonyms))
        return self._categorize_synonyms_by_language(unique_synonyms)
    
    def _categorize_synonyms_by_language(self, synonyms: List[str]) -> List[dict]:
        """æŒ‰è¯­è¨€åˆ†ç±»åŒä¹‰è¯"""
        categorized = []
        
        for synonym in synonyms:
            # æ£€æµ‹è¯­è¨€
            if self._is_english(synonym):
                categorized.append({
                    "term": synonym,
                    "language": "en",
                    "language_code": "en-US"
                })
            elif self._is_chinese(synonym):
                categorized.append({
                    "term": synonym, 
                    "language": "zh",
                    "language_code": "zh-CN"
                })
            else:
                # é»˜è®¤ä¸ºä¸­æ–‡
                categorized.append({
                    "term": synonym,
                    "language": "zh", 
                    "language_code": "zh-CN"
                })
        
        return categorized
    
    def _is_english(self, text: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºè‹±æ–‡"""
        import re
        # æ£€æŸ¥æ˜¯å¦ä¸»è¦åŒ…å«è‹±æ–‡å­—æ¯å’Œç©ºæ ¼
        english_chars = re.findall(r'[a-zA-Z\s\-]', text)
        return len(english_chars) / len(text) > 0.7 if text else False
    
    def _is_chinese(self, text: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºä¸­æ–‡"""
        import re
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
        return len(chinese_chars) > 0
    
    def _format_synonyms_for_neo4j(self, synonyms) -> str:
        """æ ¼å¼åŒ–åŒä¹‰è¯ç”¨äºNeo4jå¯¼å‡º"""
        import pandas as pd
        import json

        # å¤„ç†NaNå€¼å’Œç©ºå€¼
        if pd.isna(synonyms) or not synonyms:
            return ""

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
        if isinstance(synonyms, str):
            if synonyms.strip() == "[]" or synonyms.strip() == "":
                return ""
            try:
                synonyms = json.loads(synonyms)
            except (json.JSONDecodeError, ValueError):
                # å¦‚æœä¸æ˜¯JSONï¼Œå½“ä½œå•ä¸ªåŒä¹‰è¯å¤„ç†
                return synonyms.strip()

        # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        if not isinstance(synonyms, (list, tuple)):
            return ""

        formatted_terms = []
        for synonym_data in synonyms:
            if isinstance(synonym_data, dict):
                # æ–°æ ¼å¼ï¼šåŒ…å«è¯­è¨€ä¿¡æ¯
                term = synonym_data.get('term', '')
                lang = synonym_data.get('language', 'zh')
                if term:
                    formatted_terms.append(f"{term}({lang})")
            else:
                # å…¼å®¹æ—§æ ¼å¼ï¼šçº¯å­—ç¬¦ä¸²
                if synonym_data and str(synonym_data).strip():
                    formatted_terms.append(str(synonym_data).strip())

        return "|".join(formatted_terms)
    
    def _generate_ingredient_synonyms(self, name: str) -> List[str]:
        """ç”Ÿæˆé£Ÿæçš„åŒä¹‰è¯åˆ—è¡¨"""
        ingredient_synonym_dict = {
            # è”¬èœç±»
            "é’èŒ„å­": ["èŒ„å­", "ç´«èŒ„å­", "åœ†èŒ„"],
            "è¥¿çº¢æŸ¿": ["ç•ªèŒ„", "æ´‹æŸ¿å­"],
            "åœŸè±†": ["é©¬é“ƒè–¯", "æ´‹èŠ‹", "åœ°è›‹"],
            "çº¢è–¯": ["åœ°ç“œ", "ç”˜è–¯", "å±±èŠ‹"],
            "ç‰ç±³": ["è‹ç±³", "ç‰èœ€é»"],
            "é’æ¤’": ["æŸ¿å­æ¤’", "ç”œæ¤’", "å½©æ¤’"],
            "å¤§è‘±": ["è‘±ç™½", "éŸ­è‘±"],
            "å°è‘±": ["é¦™è‘±", "ç»†è‘±"],
            "é¦™èœ": ["èŠ«è½", "èƒ¡è½"],
            "è èœ": ["èµ¤æ ¹èœ", "æ³¢æ–¯èœ"],
            
            # è°ƒæ–™ç±»
            "ç”ŸæŠ½": ["æ·¡è‰²é…±æ²¹", "é²œå‘³é…±æ²¹"],
            "è€æŠ½": ["æ·±è‰²é…±æ²¹", "çº¢çƒ§é…±æ²¹"],
            "æ–™é…’": ["é»„é…’", "ç»å…´é…’"],
            "ç™½ç³–": ["ç»†ç ‚ç³–", "ç»µç™½ç³–"],
            "å†°ç³–": ["å†°ç‰‡ç³–", "å—ç³–"],
            "å…«è§’": ["å¤§æ–™", "èŒ´é¦™"],
            
            # è›‹ç™½è´¨ç±»
            "é¸¡è›‹": ["é¸¡å­", "åœŸé¸¡è›‹"],
            "è±†è…": ["æ°´è±†è…", "å«©è±†è…"]
        }
        
        synonyms = ingredient_synonym_dict.get(name, [])
        return self._categorize_synonyms_by_language(synonyms)
    
    def batch_process_recipes(self, recipe_dir: str, resume: bool = True) -> Tuple[int, int]:
        """æ‰¹é‡å¤„ç†èœè°±ç›®å½• - æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œåˆ†æ‰¹ä¿å­˜"""
        import glob
        
        # æ£€æŸ¥æ˜¯å¦è¦æ¢å¤ä¹‹å‰çš„è¿›åº¦
        progress_data = {}
        if resume:
            progress_data = self.load_progress()
            if progress_data:
                processed_count = progress_data.get("processed_count", 0)
                print(f"æ£€æµ‹åˆ°æœªå®Œæˆä»»åŠ¡ï¼Œå·²å¤„ç†: {processed_count} ä¸ªèœè°±")
                
                confirm = input("\næ˜¯å¦ç»§ç»­ä¹‹å‰çš„å¤„ç†? (Y/n): ").strip().lower()
                if confirm == 'n':
                    print("é‡æ–°å¼€å§‹å¤„ç†...")
                    self.processed_files.clear()
                    self.current_batch = 0
                    self.concept_id_counter = 201000000
                    # æ¸…ç†è¿›åº¦æ–‡ä»¶
                    if os.path.exists(self.progress_file):
                        os.remove(self.progress_file)
                else:
                    print("ç»§ç»­ä¹‹å‰çš„å¤„ç†...")
        
        # ä¸“é—¨æ‰«ædishesç›®å½•
        dishes_dir = os.path.join(recipe_dir, "dishes")
        if not os.path.exists(dishes_dir):
            # å¦‚æœæ²¡æœ‰dishesç›®å½•ï¼Œåˆ™æ‰«ææ•´ä¸ªç›®å½•ï¼ˆå‘åå…¼å®¹ï¼‰
            dishes_dir = recipe_dir
            print(f"æœªæ‰¾åˆ°dishesç›®å½•ï¼Œæ‰«ææ•´ä¸ªç›®å½•: {recipe_dir}")
        else:
            print(f"æ‰«æèœè°±ç›®å½•: {dishes_dir}")
        
        recipe_files = glob.glob(os.path.join(dishes_dir, "**/*.md"), recursive=True)
        
        # è¿‡æ»¤æ’é™¤çš„ç›®å½•
        filtered_files = []
        for recipe_file in recipe_files:
            relative_path = os.path.relpath(recipe_file, recipe_dir)
            path_parts = relative_path.replace('\\', '/').split('/')
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ’é™¤çš„ç›®å½•
            if any(excluded in path_parts for excluded in self.ai_agent.excluded_directories):
                continue
                
            filtered_files.append(recipe_file)
        
        recipe_files = filtered_files
        
        # è¿‡æ»¤æ‰å·²å¤„ç†çš„æ–‡ä»¶
        remaining_files = []
        for recipe_file in recipe_files:
            relative_path = os.path.relpath(recipe_file, recipe_dir)
            if relative_path not in self.processed_files:
                remaining_files.append(recipe_file)
        
        total_files = len(recipe_files)
        remaining_count = len(remaining_files)
        already_processed = len(self.processed_files)
        
        print(f"ğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
        print(f"   - æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"   - å·²å¤„ç†: {already_processed}")
        print(f"   - å¾…å¤„ç†: {remaining_count}")
        
        if remaining_count == 0:
            print("âœ… æ‰€æœ‰æ–‡ä»¶éƒ½å·²å¤„ç†å®Œæˆ!")
            return already_processed, 0
        
        processed_count = already_processed
        failed_count = 0
        current_batch_count = 0
        
        try:
            for i, recipe_file in enumerate(remaining_files):
                try:
                    with open(recipe_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    relative_path = os.path.relpath(recipe_file, recipe_dir)
                    
                    # å¤„ç†èœè°±
                    self.process_recipe(content, relative_path)
                    
                    # æ ‡è®°ä¸ºå·²å¤„ç†
                    self.processed_files.add(relative_path)
                    processed_count += 1
                    current_batch_count += 1
                    
                    # ç®€åŒ–è¿›åº¦æ˜¾ç¤º
                    if processed_count % 20 == 0:
                        progress = (processed_count / total_files) * 100
                        print(f"è¿›åº¦: {processed_count}/{total_files} ({progress:.1f}%)")
                    
                    # ä¿å­˜è¿›åº¦ï¼ˆæ¯å¤„ç†5ä¸ªæ–‡ä»¶ä¿å­˜ä¸€æ¬¡è¿›åº¦ï¼‰
                    if processed_count % 5 == 0:
                        self.save_progress(relative_path, total_files, processed_count)
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æ‰¹æ¬¡
                    if current_batch_count >= self.batch_size:
                        self.save_batch_data()

                        # é‡ç½®å½“å‰æ‰¹æ¬¡
                        self.concepts.clear()
                        self.relationships.clear()
                        self.current_batch += 1
                        current_batch_count = 0
                        
                except Exception as e:
                    failed_count += 1
                    print(f"âŒ å¤„ç†å¤±è´¥: {recipe_file} - {str(e)}")
                    continue
            
            # ä¿å­˜æœ€åä¸€ä¸ªæ‰¹æ¬¡ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
            if current_batch_count > 0:
                self.save_batch_data()
            
            # æœ€ç»ˆä¿å­˜è¿›åº¦
            self.save_progress("COMPLETED", total_files, processed_count)
            
            print(f"å¤„ç†å®Œæˆ: æˆåŠŸ {processed_count - already_processed} ä¸ªï¼Œå¤±è´¥ {failed_count} ä¸ª")
            
        except KeyboardInterrupt:
            print(f"ç”¨æˆ·ä¸­æ–­ï¼Œå·²ä¿å­˜è¿›åº¦: {processed_count}/{total_files}")

            # ä¿å­˜å½“å‰æ‰¹æ¬¡æ•°æ®
            if current_batch_count > 0:
                self.save_batch_data()

            # ä¿å­˜è¿›åº¦
            self.save_progress("INTERRUPTED", total_files, processed_count)
            
        return processed_count, failed_count
    
    def export_to_csv(self, output_dir: str):
        """å¯¼å‡ºä¸ºCSVæ ¼å¼"""
        os.makedirs(output_dir, exist_ok=True)
        
        # å¯¼å‡ºæ¦‚å¿µ
        concepts_df = pd.DataFrame(self.concepts)
        concepts_df.to_csv(os.path.join(output_dir, "concepts.csv"), 
                          index=False, encoding='utf-8')
        
        # å¯¼å‡ºå…³ç³»
        relationships_df = pd.DataFrame(self.relationships)
        relationships_df.to_csv(os.path.join(output_dir, "relationships.csv"), 
                               index=False, encoding='utf-8')
        
        print(f"CSVæ–‡ä»¶å·²å¯¼å‡ºåˆ°: {output_dir}")
        print(f"- æ¦‚å¿µæ•°é‡: {len(self.concepts)}")
        print(f"- å…³ç³»æ•°é‡: {len(self.relationships)}")
    
    def export_to_rf2_format(self, output_dir: str):
        """å¯¼å‡ºä¸ºRF2æ ‡å‡†æ ¼å¼"""
        os.makedirs(output_dir, exist_ok=True)
        
        # åˆå¹¶æ‰€æœ‰æ¦‚å¿µï¼ˆåŒ…æ‹¬é¢„å®šä¹‰æ¦‚å¿µï¼‰
        all_concepts = list(self.predefined_concepts) + self.concepts
        
        # 1. å¯¼å‡ºæ¦‚å¿µæ–‡ä»¶ (rf2_concept.txt)
        concept_headers = ["id", "effectiveTime", "active", "moduleId", "definitionStatusId"]
        with open(os.path.join(output_dir, "rf2_concept.txt"), 'w', encoding='utf-8') as f:
            f.write('\t'.join(concept_headers) + '\n')
            for concept in all_concepts:
                f.write(f"{concept['concept_id']}\t20241201\t1\t900000000\t900000000\n")
        
        # 2. å¯¼å‡ºæè¿°æ–‡ä»¶ (rf2_description.txt) - åŒ…å«åˆ«å
        desc_headers = ["id", "effectiveTime", "active", "moduleId", "conceptId", 
                       "languageCode", "typeId", "term", "caseSignificanceId"]
        
        desc_id_counter = 1
        with open(os.path.join(output_dir, "rf2_description.txt"), 'w', encoding='utf-8') as f:
            f.write('\t'.join(desc_headers) + '\n')
            
            for concept in all_concepts:
                concept_id = concept['concept_id']
                
                # å®Œå…¨é™å®šå (FSN)
                if 'fsn' in concept and concept['fsn']:
                    f.write(f"D{desc_id_counter:06d}\t20241201\t1\t900000000\t{concept_id}\t"
                           f"zh-CN\t900000003\t{concept['fsn']}\t900000000\n")
                    desc_id_counter += 1
                
                # é¦–é€‰æœ¯è¯­ (PT)
                if 'preferred_term' in concept and concept['preferred_term']:
                    f.write(f"D{desc_id_counter:06d}\t20241201\t1\t900000000\t{concept_id}\t"
                           f"zh-CN\t900000001\t{concept['preferred_term']}\t900000000\n")
                    desc_id_counter += 1
                
                # åŒä¹‰è¯ (Synonyms) - æ”¯æŒå¤šè¯­è¨€
                if 'synonyms' in concept and concept['synonyms']:
                    for synonym_data in concept['synonyms']:
                        if isinstance(synonym_data, dict):
                            # æ–°æ ¼å¼ï¼šåŒ…å«è¯­è¨€ä¿¡æ¯
                            term = synonym_data['term']
                            lang_code = synonym_data['language_code']
                        else:
                            # å…¼å®¹æ—§æ ¼å¼ï¼šçº¯å­—ç¬¦ä¸²
                            term = synonym_data
                            lang_code = "zh-CN"  # é»˜è®¤ä¸­æ–‡
                        
                        f.write(f"D{desc_id_counter:06d}\t20241201\t1\t900000000\t{concept_id}\t"
                               f"{lang_code}\t900000002\t{term}\t900000000\n")
                        desc_id_counter += 1
        
        # 3. å¯¼å‡ºå…³ç³»æ–‡ä»¶ (rf2_relationship.txt)
        rel_headers = ["id", "effectiveTime", "active", "moduleId", "sourceId", 
                      "destinationId", "relationshipGroup", "typeId", "characteristicTypeId", "modifierId"]
        
        with open(os.path.join(output_dir, "rf2_relationship.txt"), 'w', encoding='utf-8') as f:
            f.write('\t'.join(rel_headers) + '\n')
            
            rel_id_counter = 1
            for relationship in self.relationships:
                f.write(f"R{rel_id_counter:06d}\t20241201\t1\t900000000\t"
                       f"{relationship['source_id']}\t{relationship['target_id']}\t0\t"
                       f"{relationship['relationship_type']}\t900000000\t900000000\n")
                rel_id_counter += 1
        
        print(f"RF2æ ¼å¼æ–‡ä»¶å·²å¯¼å‡ºåˆ°: {output_dir}")
        print(f"- rf2_concept.txt: {len(all_concepts)} ä¸ªæ¦‚å¿µ")
        print(f"- rf2_description.txt: åŒ…å«é¦–é€‰æœ¯è¯­å’ŒåŒä¹‰è¯")
        print(f"- rf2_relationship.txt: {len(self.relationships)} ä¸ªå…³ç³»")
    
    def export_to_neo4j_csv(self, output_dir: str, merge_batches: bool = True):
        """å¯¼å‡ºä¸ºNeo4jå¯¼å…¥æ ¼å¼çš„CSV - æ”¯æŒåˆå¹¶æ‰¹æ¬¡æ•°æ®"""
        os.makedirs(output_dir, exist_ok=True)
        
        # å¦‚æœéœ€è¦åˆå¹¶æ‰¹æ¬¡æ•°æ®
        final_concepts = []
        final_relationships = []
        
        if merge_batches:
            # å…ˆå°è¯•åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡æ•°æ®
            total_concepts, total_relationships = self.merge_all_batches()
            
            # å¦‚æœæœ‰åˆå¹¶çš„æ•°æ®ï¼Œä½¿ç”¨åˆå¹¶åçš„æ•°æ®
            if total_concepts > 0:
                concepts_df = pd.read_csv(os.path.join(output_dir, "concepts.csv"))
                final_concepts = concepts_df.to_dict('records')
            else:
                final_concepts = self.concepts
                
            if total_relationships > 0:
                relationships_df = pd.read_csv(os.path.join(output_dir, "relationships.csv"))
                final_relationships = relationships_df.to_dict('records')
            else:
                final_relationships = self.relationships
        else:
            # ä½¿ç”¨å½“å‰å†…å­˜ä¸­çš„æ•°æ®
            final_concepts = self.concepts
            final_relationships = self.relationships
        
        # å‡†å¤‡èŠ‚ç‚¹æ•°æ®
        nodes_data = []
        
        # é¦–å…ˆæ·»åŠ é¢„å®šä¹‰æ¦‚å¿µ
        for predefined_concept in self.predefined_concepts:
            node = {
                "nodeId": predefined_concept["concept_id"],
                "labels": predefined_concept["concept_type"],
                "name": predefined_concept["name"],
                "preferredTerm": predefined_concept.get("preferred_term", ""),
                "fsn": predefined_concept.get("fsn", ""),
                "conceptType": predefined_concept["concept_type"],
                "synonyms": self._format_synonyms_for_neo4j(predefined_concept.get("synonyms", []))
            }
            nodes_data.append(node)
        
        # ç„¶åæ·»åŠ åŠ¨æ€ç”Ÿæˆçš„æ¦‚å¿µ
        for concept in final_concepts:
            node = {
                "nodeId": concept["concept_id"],
                "labels": concept["concept_type"],
                "name": concept["name"],
                "preferredTerm": concept.get("preferred_term", ""),
                "category": concept.get("category", ""),
                "conceptType": concept["concept_type"],
                "synonyms": self._format_synonyms_for_neo4j(concept.get("synonyms", []))
            }
            
            # æ·»åŠ ç‰¹å®šç±»å‹çš„å±æ€§
            if concept["concept_type"] == "Recipe":
                node.update({
                    "difficulty": concept.get("difficulty", ""),
                    "cuisineType": concept.get("cuisine_type", ""),
                    "prepTime": concept.get("prep_time", ""),
                    "cookTime": concept.get("cook_time", ""),
                    "servings": concept.get("servings", ""),
                    "tags": concept.get("tags", ""),
                    "filePath": concept.get("file_path", "")
                })
            elif concept["concept_type"] == "Ingredient":
                node.update({
                    "amount": concept.get("amount", ""),
                    "unit": concept.get("unit", ""),
                    "isMain": concept.get("is_main", "")
                })
            elif concept["concept_type"] == "CookingStep":
                node.update({
                    "description": concept.get("description", ""),
                    "stepNumber": concept.get("step_number", ""),
                    "methods": concept.get("methods", ""),
                    "tools": concept.get("tools", ""),
                    "timeEstimate": concept.get("time_estimate", "")
                })
            
            nodes_data.append(node)
        
        # å¯¼å‡ºèŠ‚ç‚¹
        nodes_df = pd.DataFrame(nodes_data)
        nodes_df.to_csv(os.path.join(output_dir, "nodes.csv"), 
                       index=False, encoding='utf-8')
        
        # å‡†å¤‡å…³ç³»æ•°æ®
        relationships_data = []
        for rel in final_relationships:
            relationship = {
                "startNodeId": rel["source_id"],
                "endNodeId": rel["target_id"],
                "relationshipType": rel["relationship_type"],
                "relationshipId": rel["relationship_id"]
            }
            
            # æ·»åŠ é¢å¤–å±æ€§
            for key, value in rel.items():
                if key not in ["source_id", "target_id", "relationship_type", "relationship_id"]:
                    relationship[key] = value
            
            relationships_data.append(relationship)
        
        # å¯¼å‡ºå…³ç³»
        relationships_df = pd.DataFrame(relationships_data)
        relationships_df.to_csv(os.path.join(output_dir, "relationships.csv"), 
                               index=False, encoding='utf-8')
        
        # ç”ŸæˆNeo4jå¯¼å…¥è„šæœ¬
        import_script = f"""
// Neo4j æ•°æ®å¯¼å…¥è„šæœ¬

// å¯¼å…¥èŠ‚ç‚¹
LOAD CSV WITH HEADERS FROM 'file:///nodes.csv' AS row
CREATE (n:Concept)
SET n.nodeId = row.nodeId,
    n.name = row.name,
    n.preferredTerm = row.preferredTerm,
    n.category = row.category,
    n.conceptType = row.conceptType,
    n.difficulty = toInteger(row.difficulty),
    n.cuisineType = row.cuisineType,
    n.prepTime = row.prepTime,
    n.cookTime = row.cookTime,
    n.servings = row.servings,
    n.tags = row.tags,
    n.filePath = row.filePath,
    n.amount = row.amount,
    n.unit = row.unit,
    n.isMain = toBoolean(row.isMain),
    n.description = row.description,
    n.stepNumber = toInteger(row.stepNumber),
    n.methods = row.methods,
    n.tools = row.tools,
    n.timeEstimate = row.timeEstimate;

// åˆ›å»ºç´¢å¼•
CREATE INDEX concept_id_index IF NOT EXISTS FOR (c:Concept) ON (c.nodeId);
CREATE INDEX concept_name_index IF NOT EXISTS FOR (c:Concept) ON (c.name);
CREATE INDEX concept_category_index IF NOT EXISTS FOR (c:Concept) ON (c.category);

// å¯¼å…¥å…³ç³»
LOAD CSV WITH HEADERS FROM 'file:///relationships.csv' AS row
MATCH (start:Concept {{nodeId: row.startNodeId}})
MATCH (end:Concept {{nodeId: row.endNodeId}})
CALL apoc.create.relationship(start, row.relationshipType, {{
    relationshipId: row.relationshipId,
    amount: row.amount,
    unit: row.unit,
    stepOrder: toInteger(row.step_order)
}}, end) YIELD rel
RETURN count(rel);
"""
        
        with open(os.path.join(output_dir, "neo4j_import.cypher"), 'w', encoding='utf-8') as f:
            f.write(import_script)
        
        print(f"Neo4j CSVæ–‡ä»¶å·²å¯¼å‡ºåˆ°: {output_dir}")
        print(f"- èŠ‚ç‚¹æ•°é‡: {len(nodes_data)}")
        print(f"- å…³ç³»æ•°é‡: {len(relationships_data)}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä½¿ç”¨AIæ™ºèƒ½è§£æèœè°±ç”ŸæˆçŸ¥è¯†å›¾è°±')
    parser.add_argument('recipe_dir', help='èœè°±ç›®å½•è·¯å¾„')
    parser.add_argument('-k', '--api-key', required=True, help='Kimi APIå¯†é’¥')
    parser.add_argument('-o', '--output', default='./ai_output', help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--format', choices=['csv', 'neo4j'], default='neo4j', 
                       help='è¾“å‡ºæ ¼å¼ (csv æˆ– neo4j)')
    parser.add_argument('--base-url', default='https://api.moonshot.cn/v1', 
                       help='Kimi APIåŸºç¡€URL')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(args.recipe_dir):
        print(f"é”™è¯¯: èœè°±ç›®å½•ä¸å­˜åœ¨ - {args.recipe_dir}")
        return
    
    # åˆ›å»ºAI agent
    print("åˆå§‹åŒ–Kimi AI Agent...")
    ai_agent = KimiRecipeAgent(args.api_key, args.base_url)
    
    # åˆ›å»ºçŸ¥è¯†å›¾è°±æ„å»ºå™¨
    builder = RecipeKnowledgeGraphBuilder(ai_agent, args.output)
    
    # æ‰¹é‡å¤„ç†èœè°±
    print(f"å¼€å§‹å¤„ç†èœè°±ç›®å½•: {args.recipe_dir}")
    processed, failed = builder.batch_process_recipes(args.recipe_dir)
    
    print(f"\nå¤„ç†å®Œæˆ:")
    print(f"- æˆåŠŸå¤„ç†: {processed} ä¸ªèœè°±")
    print(f"- å¤„ç†å¤±è´¥: {failed} ä¸ªèœè°±")
    
    # å¯¼å‡ºæ•°æ®
    if args.format == 'neo4j':
        builder.export_to_neo4j_csv(args.output)
    else:
        builder.export_to_csv(args.output)

if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    if len(os.sys.argv) == 1:
        print("AIèœè°±è§£æå™¨æµ‹è¯•æ¨¡å¼")
        print("è¯·æä¾›Kimi APIå¯†é’¥å’Œèœè°±ç›®å½•è·¯å¾„")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("python recipe_ai_agent.py /path/to/recipes -k YOUR_API_KEY")
    else:
        main() 