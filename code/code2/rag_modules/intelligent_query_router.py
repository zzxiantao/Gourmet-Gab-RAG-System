"""
æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨
æ ¹æ®æŸ¥è¯¢ç‰¹ç‚¹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ£€ç´¢ç­–ç•¥ï¼š
- ä¼ ç»Ÿæ··åˆæ£€ç´¢ï¼šé€‚åˆç®€å•çš„ä¿¡æ¯æŸ¥æ‰¾
- å›¾RAGæ£€ç´¢ï¼šé€‚åˆå¤æ‚çš„å…³ç³»æ¨ç†å’ŒçŸ¥è¯†å‘ç°
"""

import json
import logging
from typing import List, Dict, Tuple, Any, Optional
from dataclasses import dataclass
from enum import Enum

from langchain_core.documents import Document

logger = logging.getLogger(__name__)

class SearchStrategy(Enum):
    """æœç´¢ç­–ç•¥æšä¸¾"""
    HYBRID_TRADITIONAL = "hybrid_traditional"  # ä¼ ç»Ÿæ··åˆæ£€ç´¢
    GRAPH_RAG = "graph_rag"  # å›¾RAGæ£€ç´¢
    COMBINED = "combined"  # ç»„åˆç­–ç•¥
    
@dataclass
class QueryAnalysis:
    """æŸ¥è¯¢åˆ†æç»“æœ"""
    query_complexity: float  # æŸ¥è¯¢å¤æ‚åº¦ (0-1)
    relationship_intensity: float  # å…³ç³»å¯†é›†åº¦ (0-1)
    reasoning_required: bool  # æ˜¯å¦éœ€è¦æ¨ç†
    entity_count: int  # å®ä½“æ•°é‡
    recommended_strategy: SearchStrategy
    confidence: float  # æ¨èç½®ä¿¡åº¦
    reasoning: str  # æ¨èç†ç”±

class IntelligentQueryRouter:
    """
    æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨
    
    æ ¸å¿ƒèƒ½åŠ›ï¼š
    1. æŸ¥è¯¢å¤æ‚åº¦åˆ†æï¼šè¯†åˆ«ç®€å•æŸ¥æ‰¾ vs å¤æ‚æ¨ç†
    2. å…³ç³»å¯†é›†åº¦è¯„ä¼°ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦å›¾ç»“æ„ä¼˜åŠ¿
    3. ç­–ç•¥è‡ªåŠ¨é€‰æ‹©ï¼šè·¯ç”±åˆ°æœ€é€‚åˆçš„æ£€ç´¢å¼•æ“
    4. ç»“æœè´¨é‡ç›‘æ§ï¼šåŸºäºåé¦ˆä¼˜åŒ–è·¯ç”±å†³ç­–
    """
    
    def __init__(self, 
                 traditional_retrieval,  # ä¼ ç»Ÿæ··åˆæ£€ç´¢æ¨¡å—
                 graph_rag_retrieval,    # å›¾RAGæ£€ç´¢æ¨¡å—
                 llm_client,
                 config):
        self.traditional_retrieval = traditional_retrieval
        self.graph_rag_retrieval = graph_rag_retrieval
        self.llm_client = llm_client
        self.config = config
        
        # è·¯ç”±ç»Ÿè®¡
        self.route_stats = {
            "traditional_count": 0,
            "graph_rag_count": 0,
            "combined_count": 0,
            "total_queries": 0
        }
        
    def analyze_query(self, query: str) -> QueryAnalysis:
        """
        æ·±åº¦åˆ†ææŸ¥è¯¢ç‰¹å¾ï¼Œå†³å®šæœ€ä½³æ£€ç´¢ç­–ç•¥
        """
        logger.info(f"åˆ†ææŸ¥è¯¢ç‰¹å¾: {query}")
        
        # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†æ
        analysis_prompt = f"""
        ä½œä¸ºRAGç³»ç»Ÿçš„æŸ¥è¯¢åˆ†æä¸“å®¶ï¼Œè¯·æ·±åº¦åˆ†æä»¥ä¸‹æŸ¥è¯¢çš„ç‰¹å¾ï¼š
        
        æŸ¥è¯¢ï¼š{query}
        
        è¯·ä»ä»¥ä¸‹ç»´åº¦åˆ†æï¼š
        
        1. æŸ¥è¯¢å¤æ‚åº¦ (0-1)ï¼š
           - 0.0-0.3: ç®€å•ä¿¡æ¯æŸ¥æ‰¾ï¼ˆå¦‚ï¼šçº¢çƒ§è‚‰æ€ä¹ˆåšï¼Ÿï¼‰
           - 0.4-0.7: ä¸­ç­‰å¤æ‚åº¦ï¼ˆå¦‚ï¼šå·èœæœ‰å“ªäº›ç‰¹è‰²èœï¼Ÿï¼‰
           - 0.8-1.0: é«˜å¤æ‚åº¦æ¨ç†ï¼ˆå¦‚ï¼šä¸ºä»€ä¹ˆå·èœç”¨èŠ±æ¤’è€Œä¸æ˜¯èƒ¡æ¤’ï¼Ÿï¼‰
        
        2. å…³ç³»å¯†é›†åº¦ (0-1)ï¼š
           - 0.0-0.3: å•ä¸€å®ä½“ä¿¡æ¯ï¼ˆå¦‚ï¼šè¥¿çº¢æŸ¿çš„è¥å…»ä»·å€¼ï¼‰
           - 0.4-0.7: å®ä½“é—´å…³ç³»ï¼ˆå¦‚ï¼šé¸¡è‚‰é…ä»€ä¹ˆè”¬èœï¼Ÿï¼‰
           - 0.8-1.0: å¤æ‚å…³ç³»ç½‘ç»œï¼ˆå¦‚ï¼šå·èœçš„å½¢æˆä¸åœ°ç†ã€å†å²çš„å…³ç³»ï¼‰
        
        3. æ¨ç†éœ€æ±‚ï¼š
           - æ˜¯å¦éœ€è¦å¤šè·³æ¨ç†ï¼Ÿ
           - æ˜¯å¦éœ€è¦å› æœåˆ†æï¼Ÿ
           - æ˜¯å¦éœ€è¦å¯¹æ¯”åˆ†æï¼Ÿ
        
        4. å®ä½“è¯†åˆ«ï¼š
           - æŸ¥è¯¢ä¸­åŒ…å«å¤šå°‘ä¸ªæ˜ç¡®å®ä½“ï¼Ÿ
           - å®ä½“ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿ
        
        åŸºäºåˆ†ææ¨èæ£€ç´¢ç­–ç•¥ï¼š
        - hybrid_traditional: é€‚åˆç®€å•ç›´æ¥çš„ä¿¡æ¯æŸ¥æ‰¾
        - graph_rag: é€‚åˆå¤æ‚å…³ç³»æ¨ç†å’ŒçŸ¥è¯†å‘ç°
        - combined: éœ€è¦ä¸¤ç§ç­–ç•¥ç»“åˆ
        
        è¿”å›JSONæ ¼å¼ï¼š
        {{
            "query_complexity": 0.6,
            "relationship_intensity": 0.8,
            "reasoning_required": true,
            "entity_count": 3,
            "recommended_strategy": "graph_rag",
            "confidence": 0.85,
            "reasoning": "è¯¥æŸ¥è¯¢æ¶‰åŠå¤šä¸ªå®ä½“é—´çš„å¤æ‚å…³ç³»ï¼Œéœ€è¦å›¾ç»“æ„æ¨ç†"
        }}
        """
        
        try:
            response = self.llm_client.chat.completions.create(
                model=self.config.llm_model,
                messages=[{"role": "user", "content": analysis_prompt}],
                temperature=0.1,
                max_tokens=800
            )
            
            result = json.loads(response.choices[0].message.content.strip())
            
            analysis = QueryAnalysis(
                query_complexity=result.get("query_complexity", 0.5),
                relationship_intensity=result.get("relationship_intensity", 0.5),
                reasoning_required=result.get("reasoning_required", False),
                entity_count=result.get("entity_count", 1),
                recommended_strategy=SearchStrategy(result.get("recommended_strategy", "hybrid_traditional")),
                confidence=result.get("confidence", 0.5),
                reasoning=result.get("reasoning", "é»˜è®¤åˆ†æ")
            )
            
            logger.info(f"æŸ¥è¯¢åˆ†æå®Œæˆ: {analysis.recommended_strategy.value} (ç½®ä¿¡åº¦: {analysis.confidence:.2f})")
            return analysis
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢åˆ†æå¤±è´¥: {e}")
            # é™çº§æ–¹æ¡ˆï¼šåŸºäºè§„åˆ™çš„ç®€å•åˆ†æ
            return self._rule_based_analysis(query)
    
    def _rule_based_analysis(self, query: str) -> QueryAnalysis:
        """åŸºäºè§„åˆ™çš„é™çº§åˆ†æ"""
        # ç®€å•çš„è§„åˆ™åˆ¤æ–­
        complexity_keywords = ["ä¸ºä»€ä¹ˆ", "å¦‚ä½•", "å…³ç³»", "å½±å“", "åŸå› ", "æ¯”è¾ƒ", "åŒºåˆ«"]
        relation_keywords = ["é…", "æ­é…", "ç»„åˆ", "ç›¸å…³", "è”ç³»", "è¿æ¥"]
        
        complexity = sum(1 for kw in complexity_keywords if kw in query) / len(complexity_keywords)
        relation_intensity = sum(1 for kw in relation_keywords if kw in query) / len(relation_keywords)
        
        if complexity > 0.3 or relation_intensity > 0.3:
            strategy = SearchStrategy.GRAPH_RAG
        else:
            strategy = SearchStrategy.HYBRID_TRADITIONAL
            
        return QueryAnalysis(
            query_complexity=complexity,
            relationship_intensity=relation_intensity,
            reasoning_required=complexity > 0.3,
            entity_count=len(query.split()),
            recommended_strategy=strategy,
            confidence=0.6,
            reasoning="åŸºäºè§„åˆ™çš„ç®€å•åˆ†æ"
        )
    
    def route_query(self, query: str, top_k: int = 5) -> Tuple[List[Document], QueryAnalysis]:
        """
        æ™ºèƒ½è·¯ç”±æŸ¥è¯¢åˆ°æœ€é€‚åˆçš„æ£€ç´¢å¼•æ“
        """
        logger.info(f"å¼€å§‹æ™ºèƒ½è·¯ç”±: {query}")
        
        # 1. åˆ†ææŸ¥è¯¢ç‰¹å¾
        analysis = self.analyze_query(query)
        
        # 2. æ›´æ–°ç»Ÿè®¡
        self._update_route_stats(analysis.recommended_strategy)
        
        # 3. æ ¹æ®ç­–ç•¥æ‰§è¡Œæ£€ç´¢
        documents = []
        
        try:
            if analysis.recommended_strategy == SearchStrategy.HYBRID_TRADITIONAL:
                logger.info("ä½¿ç”¨ä¼ ç»Ÿæ··åˆæ£€ç´¢")
                documents = self.traditional_retrieval.hybrid_search(query, top_k)
                
            elif analysis.recommended_strategy == SearchStrategy.GRAPH_RAG:
                logger.info("ğŸ•¸ï¸ ä½¿ç”¨å›¾RAGæ£€ç´¢")
                documents = self.graph_rag_retrieval.graph_rag_search(query, top_k)
                
            elif analysis.recommended_strategy == SearchStrategy.COMBINED:
                logger.info("ğŸ”„ ä½¿ç”¨ç»„åˆæ£€ç´¢ç­–ç•¥")
                documents = self._combined_search(query, top_k)
            
            # 4. ç»“æœåå¤„ç†
            documents = self._post_process_results(documents, analysis)
            
            logger.info(f"è·¯ç”±å®Œæˆï¼Œè¿”å› {len(documents)} ä¸ªç»“æœ")
            return documents, analysis
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢è·¯ç”±å¤±è´¥: {e}")
            # é™çº§åˆ°ä¼ ç»Ÿæ£€ç´¢
            documents = self.traditional_retrieval.hybrid_search(query, top_k)
            return documents, analysis
    
    def _combined_search(self, query: str, top_k: int) -> List[Document]:
        """
        ç»„åˆæœç´¢ç­–ç•¥ï¼šç»“åˆä¼ ç»Ÿæ£€ç´¢å’Œå›¾RAGçš„ä¼˜åŠ¿
        """
        # åˆ†é…ç»“æœæ•°é‡
        traditional_k = max(1, top_k // 2)
        graph_k = top_k - traditional_k
        
        # æ‰§è¡Œä¸¤ç§æ£€ç´¢
        traditional_docs = self.traditional_retrieval.hybrid_search(query, traditional_k)
        graph_docs = self.graph_rag_retrieval.graph_rag_search(query, graph_k)
        
        # åˆå¹¶å’Œå»é‡
        combined_docs = []
        seen_contents = set()
        
        # äº¤æ›¿æ·»åŠ ç»“æœï¼ˆRound-robinï¼‰
        max_len = max(len(traditional_docs), len(graph_docs))
        for i in range(max_len):
            # å…ˆæ·»åŠ å›¾RAGç»“æœï¼ˆé€šå¸¸è´¨é‡æ›´é«˜ï¼‰
            if i < len(graph_docs):
                doc = graph_docs[i]
                content_hash = hash(doc.page_content[:100])
                if content_hash not in seen_contents:
                    seen_contents.add(content_hash)
                    doc.metadata["search_source"] = "graph_rag"
                    combined_docs.append(doc)
            
            # å†æ·»åŠ ä¼ ç»Ÿæ£€ç´¢ç»“æœ
            if i < len(traditional_docs):
                doc = traditional_docs[i]
                content_hash = hash(doc.page_content[:100])
                if content_hash not in seen_contents:
                    seen_contents.add(content_hash)
                    doc.metadata["search_source"] = "traditional"
                    combined_docs.append(doc)
        
        return combined_docs[:top_k]
    
    def _post_process_results(self, documents: List[Document], analysis: QueryAnalysis) -> List[Document]:
        """
        ç»“æœåå¤„ç†ï¼šæ ¹æ®æŸ¥è¯¢åˆ†æä¼˜åŒ–ç»“æœ
        """
        for doc in documents:
            # æ·»åŠ è·¯ç”±ä¿¡æ¯åˆ°å…ƒæ•°æ®
            doc.metadata.update({
                "route_strategy": analysis.recommended_strategy.value,
                "query_complexity": analysis.query_complexity,
                "route_confidence": analysis.confidence
            })
        
        return documents
    
    def _update_route_stats(self, strategy: SearchStrategy):
        """æ›´æ–°è·¯ç”±ç»Ÿè®¡"""
        self.route_stats["total_queries"] += 1
        
        if strategy == SearchStrategy.HYBRID_TRADITIONAL:
            self.route_stats["traditional_count"] += 1
        elif strategy == SearchStrategy.GRAPH_RAG:
            self.route_stats["graph_rag_count"] += 1
        elif strategy == SearchStrategy.COMBINED:
            self.route_stats["combined_count"] += 1
    
    def get_route_statistics(self) -> Dict[str, Any]:
        """è·å–è·¯ç”±ç»Ÿè®¡ä¿¡æ¯"""
        total = self.route_stats["total_queries"]
        if total == 0:
            return self.route_stats
        
        return {
            **self.route_stats,
            "traditional_ratio": self.route_stats["traditional_count"] / total,
            "graph_rag_ratio": self.route_stats["graph_rag_count"] / total,
            "combined_ratio": self.route_stats["combined_count"] / total
        }
    
    def explain_routing_decision(self, query: str) -> str:
        """è§£é‡Šè·¯ç”±å†³ç­–è¿‡ç¨‹"""
        analysis = self.analyze_query(query)
        
        explanation = f"""
        æŸ¥è¯¢è·¯ç”±åˆ†ææŠ¥å‘Š
        
        æŸ¥è¯¢ï¼š{query}
        
        ç‰¹å¾åˆ†æï¼š
        - å¤æ‚åº¦ï¼š{analysis.query_complexity:.2f} ({'ç®€å•' if analysis.query_complexity < 0.4 else 'ä¸­ç­‰' if analysis.query_complexity < 0.8 else 'å¤æ‚'})
        - å…³ç³»å¯†é›†åº¦ï¼š{analysis.relationship_intensity:.2f} ({'å•ä¸€å®ä½“' if analysis.relationship_intensity < 0.4 else 'å®ä½“å…³ç³»' if analysis.relationship_intensity < 0.8 else 'å¤æ‚å…³ç³»ç½‘ç»œ'})
        - æ¨ç†éœ€æ±‚ï¼š{'æ˜¯' if analysis.reasoning_required else 'å¦'}
        - å®ä½“æ•°é‡ï¼š{analysis.entity_count}
        
        æ¨èç­–ç•¥ï¼š{analysis.recommended_strategy.value}
        ç½®ä¿¡åº¦ï¼š{analysis.confidence:.2f}
        
        å†³ç­–ç†ç”±ï¼š{analysis.reasoning}
        """
        
        return explanation

 